---
title:  "쿠버네티스 - 아키텍처!"

read_time: false
share: false
author_profile: false
# # classes: wide

categories:
  - docker
  - kubernetes

tags: kubernetes

toc: true
toc_sticky: true

---

# 쿠버네티스 아키텍처

개요에서 간단히 다루었지만 쿠버네티스는 아래와 같은 여러개의 컴포넌트로 이루어진다.  

- 마스터 컴포넌트  
  1. `API Server`  
  2. 스케줄러  
  3. 컨트롤러 매니저  
  4. 데이터 스토어(`etcd`)  

- 노드 컴포넌트  
  1. `kubelet`  
  2. `kube-proxy`  

![kube1](/assets/k8s/kube1.png)  

위 그림과 같이 마스터 컴포넌트 모음을 통칭해 컨트롤 플레인(`Control Plane`) 이라고 한다.  

```
$ kubectl get pod -n kube-system -o custom-columns=Pod:metadata.name,Node:spec.nodeName
Pod                                Node
coredns-66bff467f8-2jvbb           minikube
coredns-66bff467f8-r8mgw           minikube
etcd-minikube                      minikube
kindnet-zt7md                      minikube
kube-apiserver-minikube            minikube
kube-controller-manager-minikube   minikube
kube-proxy-72npz                   minikube
kube-scheduler-minikube            minikube
storage-provisioner                minikube
```

실제 컨트롤 플레인을 구성하는 포드들이 `kube-system` 네임 스페이스에서 동작중이며 이를 항상 인지하고 있어야 한다.  

## Reconciliation Loops

> `Reconciliation` : 회계용어로 조정을 뜻한다. 조정은 두 레코드 세트가 일치하는지 확인하는 프로세스.  

![kube3](/assets/k8s/kube3.png)  


`Observe`: 현 상태와의 차이를 비교하기 위해 `API Server` 에 상태조회
`Diff`: 현 `context` 와 `API Server` 에서 받아온 `context` 를 비교  
`Act`: 두 `context` 간 차이가 있다면 업데이트  

## Event chain

위의 일련의 과정은 이벤트 체인이라는 이라는 관계로 형성된다.  

![kube4](/assets/k8s/kube4.png)  


1. `kubectl` 로 디플로이먼트 매니페스트를 `apply`, `kubectl`이 `디플로이먼트 API` 호출, `디플로이먼트 API`가 `etcd`에 매니페스트 정보를 저장  
2. `디플로이먼트 API`를 `watch`(감시)하고 있는 `디플로이먼트 컨트롤러`가 변화를 감지  
3. `디플로이먼트 컨트롤러`가 `리플리카셋 API` 를 호출, `리플리카셋 API`가 `etcd`에 매니페스트 정보를 저장
4. `리플리카셋 API`를 `watch`(감시)하고 있는 `리플리카셋 컨트롤러`가 변화를 감지  
5. `리플리카셋 컨트롤러`가 `파드 API` 를 호출, `파드 API`가 `etcd`에 매니페스트 정보를 저장  
6. `파드 API`를 `watch`(감시)하고 있는 `스케줄러`가 변화를 감지  
7. `스케줄러`가 어떤 노드에 파드를 배치할지 결정, `스케줄러`가 `파드 API`를 호출해 `etcd` 업데이트(어떤 노드에 배치할지)  
8. `파드 API`를 `watch`(감시)하고 있는 노드의 `kubelet`이 변화를 감지  
9. `kubelet`이 `컨테이너 런타임`에 포드 작성 지시  
10. `컨테이너` 생성  


이벤트 체인은 이 과정을 지속적으로 루프한다.  

실제 디플로이먼트를 `apply`하고 일련의 이벤트 체인 과정을 확인하고 싶다면 아래 명령 사용  

```
$ kubectl get events -w
```

```yaml
# nginx-deployment.yaml
# 기본항목
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
# 디플로이먼트 스팩
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-pod # 템플릿 검색조건
  # 파드 템플릿
  template:
    metadata:
      labels:
        app: nginx-pod
    spec:
      containers:
        - name: nginx
          image: nginx:1.15 # 컨테이너 이미지
          ports:
            - containerPort: 80
```
위의 디플로이먼트 매니페스트를 `apply` 하고 이벤트 체인에서 출력되는 메세지를확인  

```
$ kubectl get events -w
LAST SEEN   TYPE     REASON              OBJECT                        MESSAGE
0s          Normal   ScalingReplicaSet   deployment/nginx-deployment   Scaled up replica set nginx-deployment-f75fb748c to 3
0s          Normal   SuccessfulCreate    replicaset/nginx-deployment-f75fb748c   Created pod: nginx-deployment-f75fb748c-hq556
0s          Normal   SuccessfulCreate    replicaset/nginx-deployment-f75fb748c   Created pod: nginx-deployment-f75fb748c-j2sh9
1s          Normal   SuccessfulCreate    replicaset/nginx-deployment-f75fb748c   Created pod: nginx-deployment-f75fb748c-wbpzp
<unknown>   Normal   Scheduled           pod/nginx-deployment-f75fb748c-j2sh9    Successfully assigned default/nginx-deployment-f75fb748c-j2sh9 to minikube
<unknown>   Normal   Scheduled           pod/nginx-deployment-f75fb748c-hq556    Successfully assigned default/nginx-deployment-f75fb748c-hq556 to minikube
<unknown>   Normal   Scheduled           pod/nginx-deployment-f75fb748c-wbpzp    Successfully assigned default/nginx-deployment-f75fb748c-wbpzp to minikube
0s          Normal   Pulling             pod/nginx-deployment-f75fb748c-hq556    Pulling image "nginx:1.15"
0s          Normal   Pulling             pod/nginx-deployment-f75fb748c-j2sh9    Pulling image "nginx:1.15"
0s          Normal   Pulling             pod/nginx-deployment-f75fb748c-wbpzp    Pulling image "nginx:1.15"
0s          Normal   Pulled              pod/nginx-deployment-f75fb748c-hq556    Successfully pulled image "nginx:1.15"
0s          Normal   Created             pod/nginx-deployment-f75fb748c-hq556    Created container nginx
0s          Normal   Started             pod/nginx-deployment-f75fb748c-hq556    Started container nginx
0s          Normal   Pulled              pod/nginx-deployment-f75fb748c-j2sh9    Successfully pulled image "nginx:1.15"
0s          Normal   Created             pod/nginx-deployment-f75fb748c-j2sh9    Created container nginx
0s          Normal   Started             pod/nginx-deployment-f75fb748c-j2sh9    Started container nginx
0s          Normal   Pulled              pod/nginx-deployment-f75fb748c-wbpzp    Successfully pulled image "nginx:1.15"
0s          Normal   Created             pod/nginx-deployment-f75fb748c-wbpzp    Created container nginx
0s          Normal   Started             pod/nginx-deployment-f75fb748c-wbpzp    Started container nginx
```

`API Server` 에선 매니페스트 파일로 `etcd` 에 업데이트만 할뿐 이를 쿠버네티스 컨트롤러가 각각 감시하며 별도로 움직인다.  

## kubnet

`kubnet` 은 쿠버네티스 표준 네트워크 플러그인이다. 

![kube5](/assets/k8s/kube5.png)  

노드간 연결은 `10.100.0.0/16` 네트워크로 연결된다.  

노드안의 포드간의 네트워크는 클러스터 전체에서 검사 후 결정된다.  
그리고 중복되지 않는 파드 `CIDR`을 할당한다.

> 사이더(`Classless Inter-Domain Routing`): `CIDR`는 클래스 없는 도메인 간 라우팅 기법으로 1993년 도입되기 시작한, 최신의 IP 주소 할당 방법이다. https://ko.wikipedia.org/wiki/사이더_(네트워킹)

위에선 각각의 노드에 `10.1.1.0/24`, `10.1.1.1/24`를 할당했다.  

포드간의 통신지원을 위해 특정 포드에 접근할 수 있는 노드의 인터페이스를 사용자 정의 루트에 기록한다.  
쿠버네티스 내부에서 자동으로 이런 네트워크 구조와 라우팅 테이블을 유지하는 것을 기억해두자.  

# 쿠버네티스 구축  

`minikube` 툴을 사용해 간단한 학습용 클러스터를 구축해서 사용중이지만 실제 클러스터 구축에는 아래와 같은 과정을 진행해야한다.  

1. 노드간 네트워크 작성  
2. 마스터 서버 작성  
3. 마스터 서버 로드밸런서 작성  
4. 노드 서버 작성  
5. 포드간 네트워크 작성  
6. 증명서 작성과 배포  
7. `etcd` 설정 파일의 작성과 배포  
8. `etcd` 시작  
9. 쿠버네티스 설정 파일 작성과 배포  
10. 쿠버네티스 컴포넌트 배포  
11. 쿠버네티스 컴포넌트 실행  
12. 쿠버네티스 애드온 컴포넌트 작성  

다행이 이 모든 과정을 자동화 해주는 툴이 있다.  

> 만약 위의 과정을 힘들게 수동으로 처리하고 싶다면 아래 URL 참고
> https://github.com/kelseyhightower/kubernetes-the-hard-way


## 마스터 가용성  

운영중인 서비스의 가용성을 늘리려면 노드를 확보하고 파드를 늘리면 된다.  

쿠버네티스 자체의 가용성을 늘리려면 아래 그림처럼 **컨트롤 플레인**을 다중화 하여 가용성을 확보해야한다.  

![kube6](/assets/k8s/kube6.png)  

`etcd` 는 클러스터로 구축하여 서로같의 데이터를 항시 동기화 하고  

`API Server` 서버는 로드밸런서를 사용해 엑세스를 분산시킨다.  

`컨트롤러 매니저`와 `스케줄러`는 **액티브/스탠바이형**을 가지며 액티브한 마스터 컴포넌트의 장애에 대비한다. 서로간의 경합을 피하기 위해 동시간대에 하나씩의 컴포넌트만 동작한다.  

액티브한 컴포넌트는 기본값인 2초마다 갱신시간을 기록하며 
`kube-system` 네임 스페이스의 `endpoints`인 `kube-controller-manager` 에서 확인 가능하다.  

`renewTime` 속성 확인  

```
$ kubectl get endpoints kube-controller-manager -n kube-system -o yaml
apiVersion: v1
kind: Endpoints
metadata:
  annotations:
    control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"minikube_2a1b1ca1-403a-45e1-b4b8-c50afb0e14a1","leaseDurationSeconds":15,"acquireTime":"2020-04-29T16:36:09Z","renewTime":"2020-05-05T11:32:38Z","leaderTransitions":3}'
  creationTimestamp: "2020-04-28T08:17:42Z"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:control-plane.alpha.kubernetes.io/leader: {}
    manager: kube-controller-manager
    operation: Update
    time: "2020-05-05T11:32:38Z"
  name: kube-controller-manager
  namespace: kube-system
  resourceVersion: "174543"
  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-controller-manager
  uid: c38faf14-ceb3-4e54-91fd-fa730b1d58a9
```

> 컨트롤 플레인의 노드(마스터 노드)의 개수는 홀수로 하는것이 좋다. etcd 클러스터에서 노드간의 투표를 통해 데이터 동기화를 진행하기에 항상 항상 과반수가 나오는 홀수를 권장하며 3 ~ 7개 까지의 노드수가 효율적이다.  

## 노드 가용성  

일반 노드에선 컨트롤 플레인에서 고려할 각종 문제점이 없기에  
가용성, 다중화가 필요하다면 노드(서버)를 추가확보하기만 하면 된다.  

단 노드 다운시 해당 노드에 존재하던 파드들이 다른 노드에 배치되기에 리소스를 확인하며 노드확보할 필요가 있다.  
노드 2개 운영시 하나의 노드가 다운될 경우 다른 하나의 노드에 부하가 집중됨으로 노드는 3개 이상으로 구성하는것이 전형적인 구조이다.  

### 노드 인프라스트럭처  

가장큰 리소스인 노드부터 가장작은 파드, 각종 컴포넌트들의 다중화를 진행하였어도  
**폭발반경(Blast Radius)**을 계산하지 않는다면 물리적 장애 발생시 대처가 불가능하다.  

폭발반경의 범위는 아래와 같다.  

1. 물리서버  
2. 랙  
3. 데이터 센터  
4. 지역  

만약 하나의 물리서버에 가상머신을 사용해 모든 서버를 올리게 되면 해당 물리서버 다운시 모든 서비스가 중단된다.  
만약 하나의 랙에 모든 서비스 운영 물리서버를 설치한다면 해당 랙의 전력이나 네트워크 다운시 모든 서비스가 중단된다.  
데이터 센터나 지역도 마찬가지이다. 재난 발생시에 전력, 네트워크가 차단될 경우 모든 서비스가 중단된다.  

폭발반경을 의식하며 동일한 종류의 서버(노드, 컨트롤 플레인), 가상머신을 분리 배치해야한다.  

데이터센터 폭발반경을 의식해 쿠버네티스 리소스를 분산배치할 경우 동기화 스르풋, 타임아웃이 될 위험이 발생한다.  
컨트롤 플레인의 경우 특히 더 민감한데 하트비트 100밀리초, 리더선출 1000밀리초를 기본값으로 사용한다. 

애저의 경우 한국 중부, 남부지역의 지연시간은 10밀리초 정도라한다.  
전용 네트워크 백본을 통해 연결되기에 이보다 더 빨라질순 없다.  

만약 목표를 10밀리초 이하로 잡아야 한다면 별도에 지역에 클러스터 하나를 구축하는것이 아닌
하나의 지역마다 클러스터 하나를 구축해야 한다.  

## 업데이트, 업그레이드  

쿠버네티스 클러스터 운영시 2가지의 버전업이 필요하다.  

1. 쿠버네티스 컴포넌드 버전업  
2. 쿠버네시트 서버 버전업  

쿠버네티스는 마이너는 3개월 간격으로 버전이 릴리즈 되고 있으며 단순 버그 패치는 한달에 한두번 릴리즈 되고 있다.  

### Cordon, Uncordon, Drain


업데이트시에 노드의 재부팅이 빈번히 일어남으로 쿠버네티스 스케줄링에서 제외해야 한다.  
이때 `Cordon`, `Uncordon` 명령을 사용한다.

> `Cordon`: 폐쇄하다  

다음과 같은 간단한 `Deployment`를 apply  

```yaml
# nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
```

```
$ kubectl apply -f nginx.yaml
$ kubectl get pod --output=wide
NAME                    READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
nginx-f89759699-5pqrm   1/1     Running   0          96s   172.18.0.2   minikube-m03   <none>           <none>
nginx-f89759699-7pmmz   1/1     Running   0          96s   172.18.0.2   minikube-m02   <none>           <none>
nginx-f89759699-wxjtx   1/1     Running   0          96s   172.18.0.3   minikube-m03   <none>           <none>

$ kubectl cordon minikube-m02
node/minikube-m02 cordoned

$ kubectl get node
NAME           STATUS                     ROLES    AGE    VERSION
minikube       Ready                      master   143m   v1.18.0
minikube-m02   Ready,SchedulingDisabled   <none>   141m   v1.18.0
minikube-m03   Ready                      <none>   11m    v1.18.0
```

`minikube-m02` 노드를 `cordon` 명령을 통해 스케줄링에서 제외한다.  

`STATUS` 에 `SchedulingDisabled` 상태가 추가된 것을 확인  

이 상태에서 `replicas` 를 6으로 변경한다.  

```
$ kubectl get pod --output=wide
NAME                    READY   STATUS    RESTARTS   AGE     IP           NODE           NOMINATED NODE   READINESS GATES
nginx-f89759699-5pqrm   1/1     Running   0          3h25m   172.18.0.2   minikube-m03   <none>           <none>
nginx-f89759699-7pmmz   1/1     Running   0          3h25m   172.18.0.2   minikube-m02   <none>           <none>
nginx-f89759699-fnfst   1/1     Running   0          23s     172.18.0.5   minikube-m03   <none>           <none>
nginx-f89759699-mcpj2   1/1     Running   0          23s     172.18.0.6   minikube-m03   <none>           <none>
nginx-f89759699-tmhz2   1/1     Running   0          23s     172.18.0.4   minikube-m03   <none>           <none>
nginx-f89759699-wxjtx   1/1     Running   0          3h25m   172.18.0.3   minikube-m03   <none>           <none>
```

`minikube-m02`에는 추가되지 않고 `minikube-m03`에만 파드가 추가생성되었다.   

`minikube-m02`를 `Uncordon` 명령으로 스케줄링 대상으로 복원

```
$ kubectl uncordon minikube-m02
node/minikube-m02 uncordoned

$ kubectl get node
NAME           STATUS   ROLES    AGE     VERSION
minikube       Ready    master   5h48m   v1.18.0
minikube-m02   Ready    <none>   5h46m   v1.18.0
minikube-m03   Ready    <none>   3h36m   v1.18.0
```

`Drain`은 `Cordon` 움직임에 포드의 삭제, 재작성을 더한것이다.  

```
$ kubectl drain minikube-m03
node/minikube-m03 cordoned
error: unable to drain node "minikube-m03", aborting command...

There are pending nodes to be drained:
 minikube-m03
error: cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kindnet-v7qmx, kube-system/kube-proxy-b6r9k
```

노드 전용으로 움직이는 데몬셋은 다른 노드로 옮기수 없기에 오류가 발생한다.  

```
$ kubectl drain minikube-m03 --ignore-daemonsets
node/minikube-m03 already cordoned
WARNING: ignoring DaemonSet-managed Pods: kube-system/kindnet-v7qmx, kube-system/kube-proxy-b6r9k
evicting pod default/nginx-f89759699-fnfst
evicting pod default/nginx-f89759699-5pqrm
evicting pod default/nginx-f89759699-mcpj2
evicting pod default/nginx-f89759699-tmhz2
evicting pod default/nginx-f89759699-wxjtx
pod/nginx-f89759699-mcpj2 evicted
pod/nginx-f89759699-wxjtx evicted
pod/nginx-f89759699-fnfst evicted
pod/nginx-f89759699-tmhz2 evicted
pod/nginx-f89759699-5pqrm evicted
node/minikube-m03 evicted

$ kubectl get node
NAME           STATUS                     ROLES    AGE     VERSION
minikube       Ready                      master   5h54m   v1.18.0
minikube-m02   Ready                      <none>   5h52m   v1.18.0
minikube-m03   Ready,SchedulingDisabled   <none>   3h42m   v1.18.0

$ kubectl get pod --output=wide
NAME                    READY   STATUS    RESTARTS   AGE     IP           NODE           NOMINATED NODE   READINESS GATES
nginx-f89759699-5nh2s   1/1     Running   0          91s     172.18.0.5   minikube-m02   <none>           <none>
nginx-f89759699-7pmmz   1/1     Running   0          3h33m   172.18.0.2   minikube-m02   <none>           <none>
nginx-f89759699-9x2gq   1/1     Running   0          91s     172.18.0.6   minikube-m02   <none>           <none>
nginx-f89759699-jxdbq   1/1     Running   0          91s     172.18.0.3   minikube-m02   <none>           <none>
nginx-f89759699-kdtqs   1/1     Running   0          91s     172.18.0.4   minikube-m02   <none>           <none>
nginx-f89759699-pp4kh   1/1     Running   0          91s     172.18.0.7   minikube-m02   <none>           <none>
```

> `evicted`: 퇴거

`drain` 설정한 노드의 파드는 모두 다른 노드에 재작성 되고 스케줄링에서 제외된다.  

<!-- ### Kured (Kubernetes Rebooot Daemon)

노드 재시작시 Cordon, Drain 의 명령을 통해 수동으로 스케줄링에서 제외시킬 수 있다.  
`Kured` 을 사용하면 자동으로 재시작이 필요한 노드를 감지하고 클러스터 전체에 대한 영향을 고려해 reboot 한다.   -->


# 네임스페이스

네임스페이스는 하나의 클러스터를 여러개의 논리적 단위로 나눠 사용하기 윈한 기능으로 
클러스터 하나를 여러 팀이 함께 공유할 수 있음.  

> https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/namespaces/

`Pod` 를 포함한 각종 쿠버네티스 리소스를 그룹화, 다른 그룹끼리는 분리화 하는 기능을 지원한다.  

네임스페이스만 다르면 동일한 리소스 네임을 사용할 수 있다.   
> 단 노드는 동일한 리소스명 사용 불가능  

쿠버네티스 설치시 자동으로 생성하는 네임스페이스들은 아래와 같다.  

```
$ kubectl get namespace
NAME              STATUS   AGE
default           Active   6d4h 
kube-public       Active   6d4h 
kube-system       Active   6d4h 
kube-node-lease   Active   6d4h 
```

* `default`: 기본 공간, 명령을 실행시 별도의 네임스페이스를 지정하지 않을경우 `default` 네임스페이스에 명령을 적용한다.  
* `kube-public`: 클러스터의 공용 공간, `ConfigMap` 같은 데이터가 저장되며 리소스 모니터링용으로 자주 사용된다.  
* `kube-system`:  쿠버네티스 시스템에서 관리하는 네임스페이스, 시스템 관리용 네임스페이스  
* `kube-node-lease`: 노드의 임대 오브젝트(`Lease object`)들을 관리하는 네임스페이스  

네임스페이스 내부에서 돌아가는 `pod` 목록 확인하면 아래와 같다.  

```
$ kubectl get pods --all-namespaces
NAMESPACE     NAME                                     READY   STATUS    RESTARTS   AGE
default       nginx-app-d6ff45774-nlvc8                1/1     Running   0          85m
default       nginx-app-d6ff45774-xwb82                1/1     Running   0          85m
kube-system   coredns-f9fd979d6-27z5q                  1/1     Running   0          177m
kube-system   coredns-f9fd979d6-z78k8                  1/1     Running   0          177m
kube-system   etcd-docker-desktop                      1/1     Running   0          176m
kube-system   kube-apiserver-docker-desktop            1/1     Running   0          176m
kube-system   kube-controller-manager-docker-desktop   1/1     Running   0          176m
kube-system   kube-proxy-g52r7                         1/1     Running   0          177m
kube-system   kube-scheduler-docker-desktop            1/1     Running   2          176m
kube-system   storage-provisioner                      1/1     Running   2          176m
kube-system   vpnkit-controller                        1/1     Running   0          176m
```

많은 종류의 파드가 `kube-system` 에 설정되어 동작하고 있고 새로만든 nginx 의 경우 기본 공간인 default 를 사용한다.  
지금까지 별도의 `namespace` 를 지정해서 `pod` 를 생성한적이 없기때문에 모두 `default` 네임스페이스에 포함되어 있을것.  

## 네임스페이스 생성  

```yaml
# 
apiVersion: v1
kind: Namespace
metadata:
  name: trade-system
```

`kind: Namespace` 를 사용해 네임스페이스 생성  

```
$ kubectl create -f Namespace/namespace.yaml
namespace/trade-system created

$ kubectl get namespaces
NAME              STATUS   AGE
default           Active   6d4h
kube-node-lease   Active   6d4h
kube-public       Active   6d4h
kube-system       Active   6d4h
trade-system      Active   8s
```

선호하는 네임스페이스를 지속적으로 사용하기 위해 컨텍스트를 생성하고 해당 설정을 저장.  

```
$ kubectl config set-context my-context --namespace=trade-system
Context "my-context" created.

$ kubectl config get-contexts
CURRENT   NAME         CLUSTER    AUTHINFO   NAMESPACE
*         minikube     minikube   minikube
          my-context                         trade-system

$ kubectl config use-context my-context # 컨텍스트 변경 가능    
Switched to context "my-context".
```

삭제명령  

```
$ kubectl delete -f Namespace/namespace.yaml
namespace "trade-system" deleted
```

# 쿠버네티스 네트워킹

쿠버네티스에선 컨테이너간 통신, kuberctl 을통한 명령어 실행을 해야하는데 쿠버네티스 네트워킹을 알아보자.  


## 리눅스 네임스페이스  

> `Namespace`: 한덩어리의 데이터에 이름을 붙혀 충돌 가능성을 줄이고, 쉽게 참조할 수 있게하는 개념

`Linux` 커널의 `namespace` 기능은 Linux의 오브젝트에 이름을 붙임으로써 다음과 같은 6개의 독립된 환경을 구축할 수 있다.

1. PID namespace  
  프로세스에 할당된 고유한 ID를 말하며 이를 통해 프로세스를 격리할 수 있다
  namespace가 다른 프로세스 끼리는 서로 액세스할 수 없다

2. Network namespace  
  네트워크 디바이스, IP 주소, Port 번호, 라우팅 테이블, 필터링테이블 등의 네트워크 리소스를 namespace마다 격리시켜  
  독립적으로 가질 수 있다. 이 기능을 이용하면 OS 상에서 사용중인 Port가 있더라도 컨테이너 안에서 동일한 Port를 사용 가능하다.

3. UID namespace  
  UID, GID를 namespace 별로 독립적으로 가질 수 있도록 한다.  
  namespace 안과 호스트 OS 상에서 서로 다른 UID, GID를 가질 수 있다.  

4. Mount namespace  
  호스트 OS와 namespace가 서로 다른 격리된 파일시스템 트리를 가질 수 있도록 한다  
  마운트는 컴퓨터에 연결된 기기나 기억장치를 OS에 인식시켜 사용가능한 상태로 만드는 것을 의미한다

5. UTS namespace  
   namespace 별로 호스트명이나 도메인 명을 독자적으로 가질 수 있다  

6. IPC namespace  
  프로세스간 통신(IPC) 오브젝트를 namespace 별로 독립적으로 가질 수 있다


## 도커 네트워크 구조  

일반적인 도커 환경의 네트워크 구조

![docker4](/assets/2019/docker4.png)

`docker0` 라는 브리지를 생성해 컨테이너가 생성될 때 마다 `virtual ethernet` 가 생성되고 이를 통해 컨테이너와 호스트를 연결한다.  

생성된 각 컨테이너는 네트워크 네임스페이스 안에서 서로의 ARP, 라우팅 테이블을 관리하고  
`docker0` 밑에서 생성된 네트워크 네임스페이스를 `도커 디폴트 네트워크 네임스페이스` 라 한다.  

## 파드 네트워크 구조

쿠버네티스에선 하나의 파드에 하나의 `virtual ethernet` 생성되고 하나의 IP 를 사용한다.  
여러개의 컨테이너가 이 하나의 IP 를 공유한다.  

![kucbe11](/assets/k8s/kube11.png)  
> 출처: https://velog.io/@seunghyeon/쿠버네티스-네트워크-구성도

같은 파드의 컨테이너끼리는 localhost 를 통해 통신 가능하다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: podnet-01
spec:
  containers:
   - name: web
     image: nginx
   - name: ubuntu
     image: ubuntu:16.04
     command: ["/bin/sh", "-c", "while : ;do curl http://localhost:80/; sleep 10; done"]
```

생성된 ubuntu 컨테이너가 localhsot 80 요청도 문제없이 수행된다.  

## 네트워크 플러그인 - CNI(Container Network Interface) 

노드와 파드가 모두 하나라면 `localhost` 주소를 통해 통신이 가능하겠지만  
클러스터는 여러개의 노드와 여러개의 파드로 구성된다.  

쿠버네티스에서는 파드 각각이 모두 고유의 IP를 갖도록 구성하기에 `CNI(Container Network Interface)`라는 기술을 사용한다.  


![kucbe12](/assets/k8s/kube12.png)  
> 출처: https://github.com/dybooksIT/kubernetes-book/blob/master/readme/errata/errata.md

`CNI`가 각 파드마다 별도의 IP대역을 설정하고  
`CNI`는 이외에도 아래와 같은 기능들을 수행한다.  

* 커널 라우팅  
* 동적 라우팅  
* Pod 인터페이스 생성 및 IP, Subnet, Routing Table 설정  
* Proxy ARP 기능  


`CNI` 기능을 수행하는 여러 플러그인(플라넬, 칼리코, 실리엄) 이 있으며 네트워크 플러그인에 따라서 호스트 네트워크를 구성하는 방법과 특성이 다르다.  

### 서비스 네트워크

`Pod` 간 통신은 IP대역만으로 통신하지는 않고  
앞단에 `Service` 를 통해 이루어진다.  

서비스가 생성되면 각 서비스IP와 파드 네트워크를 매핑한 `NAT` 테이블이 생성되고

![kucbe13](/assets/k8s/kube13.png)  
> 출처: https://arisu1000.tistory.com/27851?category=787056

각 노드 NAT 에 100 대역을 가진 서비스용 IP 가 추가되며 이 IP 로 접근시 파드로의 접근이 진행된다.  

> 모든 노드 안에는 `kube-proxy` 가 설치되어 있으며 각 `kube-proxy` 가 `NAT` 테이블을 만든다. 성능이슈로 `kube-proxy` 이 직적 패킷을 받지 않고 iptables 만 수정하며 실제 패킷은 넷필터(netfilter) 가 처리한다.  

`NodePort` 로 만들시에는 각 클러스터의 NAT 에만 추가되는 것이 아닌 게이트웨이에도 라우팅 테이블이 추가된다.  

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: podnet-02
  labels:
    service-name: podnet-02
spec:
  containers:
  - name: my-nginx
    image: nginx
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport
spec:
  type: NodePort
  selector:
    service-name: podnet-02
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
```

`pod` 와 `service` 추가

```
$ kubectl get pods -o wide
NAME                           READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES
podnet-02                      1/1     Running   0          71s     10.233.117.155   instance-2   <none>           <none>

$ kubectl describe service nginx-nodeport 
Name:                     nginx-nodeport
Namespace:                default
Labels:                   <none>
Annotations:              <none>
Selector:                 service-name=podnet-02
Type:                     NodePort
IP Families:              <none>
IP:                       10.233.40.46 - service 에게 할단된 nat ip
IPs:                      10.233.40.46
Port:                     <unset>  80/TCP - service 의 cluster 포트
TargetPort:               80/TCP
NodePort:                 <unset>  30640/TCP - service 의 node 포트
Endpoints:                10.233.117.155:80 - 목적지 ip:port (podnet)
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>
```





# 쿠버네티스 DNS (CoreDNS)  

클러스터 안에서 도메인 사용을 위해 `CoreDNS` 시스템을 사용한다.  
파드간 통신에서 클러스터 안에서만 사용하는 DNS를 설정해서 사용한다.  

`서비스이름.네임스페이스이름.svc.cluster.local`

```yaml
apiVersion: v1
kind: Service
metadata:
  namespace: monitoring
  labels:
    app: prometheus-app
  name: prometheus-app
spec:
  type: NodePort
  ports:
    - nodePort: 30990
      port: 9090
      targetPort: 9090
  selector:
    app: prometheus-app
```

만약 위와같은 service 정의시에 도메인은 아래와 같다.  

`prometheus-app.monitoring.svc.cluster.local`

파드에 접근할 수 있는 도메인 `호스트네임이름.서브도메인이름.네임스페이스이름.svc.cluster.local` 

> pod 라도 `.svc` 형식의 도메인을 사용한다.

## DNS 질의 구조  

쿠버네티스에서는 처음에 `kube-dns`라는 DNS를 사용했지만 업데이트 되면서 `CoreDNS`를 사용중이다.   
DNS 질의 우선순위가 있으며 `.spec.dnsPolicy` 를 통해 우선순위 조절이 가능하다.  

1. Default - 노드의 DNS 설정
2. ClusterFirst - 클러스터 외부 DNS에 질의
3. ClusterFirstWithHostNet - 파드를 호스트 모드로 사용하겠다고 설정하는 hostNetwork  
4. None - 쿠버네티스 클러스터 안 DNS 설정을 무시  

`CoreDNS`는 모듈 형식으로 `CoreDns` 파드 안에 `coredns`라는 컨테이너 하나가 존재한다.  

`kube-system` 네임스페이스에 `coredns` 컨피그맵으로 `Corefile` 관리

```
$ kubectl describe configmap coredns -n kube-system
```