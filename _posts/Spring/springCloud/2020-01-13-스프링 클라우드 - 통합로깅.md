---
title:  "spring cloud - 통합로깅!"

read_time: false
share: false
author_profile: false
classes: wide

categories:
  - spring

tags:
  - eureka
  - spring-cloud

toc: true

---

## 스프링 클라우드 로그처리

아무래도 각 클라우드에 흩어져 있는 서비스의 로그를 관리하려면 일반적인 파일 시스템 형식의 로그로는 관리가 불가능하다.  

`ELK stack`은 이러한 문제점을 해결해주는 훌륭한 검색엔진 및 관리툴로써 로그를 온라인으로 저장받아 한곳에 모아 관리할수 있게 해주는 오픈소스이다.  

### ELK 설치(docker)

> https://github.com/deviantony/docker-elk

`docker-compose`로 쉽게 설치할 수 있도록 만들어준 git hub,  
`git-clone`으로 다운받은 후 설치하자.  

`MAC`에서 `docker`환경설정하기  

```
screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty
sysctl -w vm.max_map_count=262144
```

설지 전에 logstash, kibana, elasticsearch 의 설정파일을 변경해야한다.  
모든 설정파일에서 라이센스가 필요한 xpack 설정은 모두 주석처리하자.
 
 또한 logstash 의 경우 모든 데이터를 json형태로 저장할 것이기 때문에 `input` 객체 설정.  

```conf
input {
	tcp {
		port => 5000
		codec => json
	}
}
## Add your filters / logstash plugins configuration here
output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "changeme"
	}
}
```
 
만약 `reverse proxy`를 사용중이라면 `server.basePath`를 위해 `kibana.yml` 설정파일에 `server.basePath` 를 추가해 쉽게 프록시 환경을 구축할 수 있도록 설정.  

```yml
## Default Kibana configuration from Kibana base image.
## https://github.com/elastic/kibana/blob/master/src/dev/build/tasks/os_packages/docker_generator/templates/kibana_yml.template.js
#
server.name: kibana
server.host: "0"
server.basePath: /kibana
elasticsearch.hosts: [ "http://elasticsearch:9200" ]
#xpack.monitoring.ui.container.elasticsearch.enabled: true

## X-Pack security credentials
#
elasticsearch.username: elastic
elasticsearch.password: changeme
```
 
`nginx.conf`파일에서 아래처럼 설정하면 된다.  

```conf
location /kibana/ {
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header Host $http_host;
    proxy_pass http://localhost:5601/;
}
# 주의: 뒤에 `/`를 꼭 붙이도록 하자.  
```


extensions의 `curator`를 통해 저장 로그가 유지되는 시간설정이 가능하다.  
`delete_log_files_curator.yml`의 `unit_count`에 90을 설정, 3개월간 유지하도록 설정한다.  

실행전에 `$ELK_VERSION` 를 환경변수에 등록,  
`env ELK_VERSION=7.5.1`   

설정이 끝났으면 아래 명령을 통해 `elk`와 `curator`까지 같이 실행되도록 `docker-compose` 명령 실행 

```
$ docker-compose -f docker-compose.yml -f extensions/curator/curator-compose.yml up -D
```

### spring logback log설정

`pom.xml`에 아래 `dependency`추가  
```xml
<dependency>
  <groupId>net.logstash.logback</groupId>
  <artifactId>logstash-logback-encoder</artifactId>
  <version>4.11</version>
</dependency>
```
`logback-spring.xml`파일을 추가한다.  

```xml
<configuration>
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>INFO</level>
        </filter>
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} %-5level %msg%n</pattern>
            <charset>utf8</charset>
        </encoder>
    </appender>
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/order.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>order.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>10</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} %-5level %msg%n</pattern>
        </encoder>
    </appender>
    <appender name="STASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>localhost:5555</destination>
        <encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
            <providers>
                <mdc/>
                <context/>
                <logLevel/>
                <loggerName/>
                <pattern>
                    <pattern>
                        {"appName": "order-service"}
                    </pattern>
                </pattern>
                <threadName/>
                <message/>
                <logstashMarkers/>
                <stackTrace/>
            </providers>
        </encoder>
    </appender>
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="FILE"/>
        <appender-ref ref="STASH"/>
    </root>
</configuration>
```

실제 `localhost/kibana/`에 접속해서 로그가 쌓이는지 확인하자.  

> 프록시 설정을 하지 않았다면 `localhost:5601` 로 접속