---
title:  "spring cloud - 통합로깅!"

read_time: false
share: false
author_profile: false
toc: true
toc_sticky: true
# classes: wide

categories:
  - spring-cloud
---


아무래도 각 클라우드에 흩어져 있는 서비스의 로그를 관리하려면 일반적인 파일 시스템 형식의 로그로는 관리가 불가능하다.  

`ELK stack`은 이러한 문제점을 해결해주는 훌륭한 검색엔진 및 관리툴로써 로그를 온라인으로 저장받아 한곳에 모아 관리할수 있게 해주는 오픈소스이다.  

## ELK 설치(docker)

> https://github.com/deviantony/docker-elk

`docker-compose`로 쉽게 설치할 수 있도록 만들어준 깃 허브 페이지  

`MAC`에서 `docker`환경설정하기  

```
screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty
sysctl -w vm.max_map_count=262144
```

설지 전에 `logstash`, `kibana`, `elasticsearch` 의 설정파일을 변경해야한다.  

`elasticsearch.yml` 파일에서 trial 로 적힌 속성을 아래와 같이 변경  
`xpack.license.self_generated.type: basic`

 
또한 `logstash/pipeline/logstach.conf` 의 경우 모든 데이터를 `json` 형태로 저장할 것이기 때문에 `input` 객체 설정.  

```conf
input {
	tcp {
		port => 5000
		codec => json
	}
}
## Add your filters / logstash plugins configuration here
output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "changeme"
	}
}
```

extensions의 `curator`를 통해 저장 로그가 유지되는 시간설정이 가능하다.  

`extensions/curator/config/delete_log_files_curator.yml`의 `UNIT_COUNT`에 90을 설정, 3개월간 유지하도록 설정한다.  

실행전에 `$ELK_VERSION`, `UNIT_COUNT` 를 환경변수에 등록,  

`ELK_VERSION=7.5.1`, `UNIT_COUNT=90`  

설정이 끝났으면 아래 명령을 통해 `elk`와 `curator`까지 같이 실행되도록 `docker-compose` 명령 실행 

```
$ docker-compose -f docker-compose.yml -f extensions/curator/curator-compose.yml up -d
```

### spring logback log설정

logstash 를 사용하려면 아래 dependency 를 추가해야한다.  

```xml
<dependency>
  <groupId>net.logstash.logback</groupId>
  <artifactId>logstash-logback-encoder</artifactId>
  <version>4.11</version>
</dependency>
```

각 서비스에 아래와 같은 `logback-local.xml` 파일을 추가 후 `logging.config=classpath:logback-local.xml` 설정  

```xml
<configuration>
    <statusListener class="ch.qos.logback.core.status.OnConsoleStatusListener"/>
    <contextName>sample-spring-cloud</contextName>
    <property resource="bootstrap.properties"/>
    <property name="logHome" value="${HOME}/sample-spring-cloud/logs"/>
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %logger{50} - %msg%n</pattern>
            <charset>utf8</charset>
        </encoder>
    </appender>
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${logHome}/%d{yyyyMMdd}/${spring.application.name}.%d{yyyyMMdd}.%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>15MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <maxHistory>90</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %logger{50} - %msg%n</pattern>
            <charset>utf8</charset>
        </encoder>
    </appender>


    <appender name="STASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>localhost:5000</destination>
        <encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
            <providers>
                <mdc/>
                <context/>
                <logLevel/>
                <loggerName/>
                <pattern>
                    <pattern>
                        {"appName": "sample-spring-cloud-${spring.application.name}"}
                    </pattern>
                </pattern>
                <threadName/>
                <message/>
                <logstashMarkers/>
                <stackTrace/>
            </providers>
        </encoder>
    </appender>
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="FILE"/>
        <appender-ref ref="STASH"/>
    </root>
</configuration>
```

실제 `localhost:5601`에 접속해서 로그가 쌓이는지 확인하자.  


`sleuth` 를 추가설정하면 logstash 로 날아가는 request header 에 spanId, traceId 가 추가되어 전달됨으로 endpoint 간의 request 추적이 가능하다.  

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>
```


## zipkin

zipkin는 slueth 를 사용하는 분산추적 시스템으로 조금더 시각적으로 로그를 출력한다.  

### zipkin install  
 
> https://zipkin.io/pages/quickstart.html

```
$ docker run -d -p 9411:9411 openzipkin/zipkin
```

`http://localhost:9411/zipkin/` 로 접속해보자.  

중앙 집줍 로깅이 필요한 서비스에서 아래 `dependency` 와 속성을 추가  

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-zipkin</artifactId>
</dependency>
```

```
spring.zipkin.base-url=http://localhost:9411/
```

서비스간의 메세지 성공/실패 빈도, `request`의 `trace id` 를 검색해 어디서 실패했는지 추적가능하다.  

![zipkin](/assets/2020/zipkin1.png){: .shadow}  

> `zipkin-server` 는 `spring boot 2.x` 버전을 지원하지 않음으로 공식 홈페이지 quick start 에서 기본제공하는 서버를 사용해야함.   
> 만약 커스텀이 필요하다면 `https://github.com/openzipkin/zipkin/tree/master/zipkin-server` 을 다운받아 진행해야한다.  

