---
title:  "쿠버네티스 - 아키텍처!"

read_time: false
share: false
author_profile: false
# # classes: wide

categories:
  - docker
  - kubernetes

tags: kubernetes

toc: true
toc_sticky: true

---

# 쿠버네티스 아키텍처

개요에서 간단히 다루었지만 쿠버네티스는 아래와 같은 여러개의 컴포넌트로 이루어진다.  

- 마스터 컴포넌트  
  1. `API Server`  
  2. 스케줄러  
  3. 컨트롤러 매니저  
  4. 데이터 스토어(`etcd`)  

- 노드 컴포넌트  
  1. `kubelet`  
  2. `kube-proxy`  

![kube1](/assets/2020/kube1.png)  

위 그림과 같이 마스터 컴포넌트 모음을 통칭해 컨트롤 플레인(`Control Plane`) 이라고 한다.  

```
$ kubectl get pod -n kube-system -o custom-columns=Pod:metadata.name,Node:spec.nodeName
Pod                                Node
coredns-66bff467f8-2jvbb           minikube
coredns-66bff467f8-r8mgw           minikube
etcd-minikube                      minikube
kindnet-zt7md                      minikube
kube-apiserver-minikube            minikube
kube-controller-manager-minikube   minikube
kube-proxy-72npz                   minikube
kube-scheduler-minikube            minikube
storage-provisioner                minikube
```

실제 컨트롤 플레인을 구성하는 포드들이 `kube-system` 네임 스페이스에서 동작중이며 이를 항상 인지하고 있어야 한다.  

## Reconciliation Loops

> Reconciliation : 회계용어로 조정을 뜻한다. 조정은 두 레코드 세트가 일치하는지 확인하는 프로세스입니다.  

![kube3](/assets/2020/kube3.png)  


`Observe`: 현 상태와의 차이를 비교하기 위해 `API Server` 에 상태조회
`Diff`: 현 `context` 와 `API Server` 에서 받아온 `context` 를 비교  
`Act`: 두 `context` 간 차이가 있다면 업데이트  

## Event chain

위의 일련의 과정은 이벤트 체인이라는 이라는 관계로 형성된다.  

![kube4](/assets/2020/kube4.png)  


1. `kubectl` 로 디플로이먼트 매니페스트를 `apply`, `kubectl`이 `디플로이먼트 API` 호출, `디플로이먼트 API`가 `etcd`에 매니페스트 정보를 저장  
2. `디플로이먼트 API`를 `watch`(감시)하고 있는 `디플로이먼트 컨트롤러`가 변화를 감지  
3. `디플로이먼트 컨트롤러`가 `리플리카셋 API` 를 호출, `리플리카셋 API`가 `etcd`에 매니페스트 정보를 저장
4. `리플리카셋 API`를 `watch`(감시)하고 있는 `리플리카셋 컨트롤러`가 변화를 감지  
5. `리플리카셋 컨트롤러`가 `파드 API` 를 호출, `파드 API`가 `etcd`에 매니페스트 정보를 저장  
6. `파드 API`를 `watch`(감시)하고 있는 `스케줄러`가 변화를 감지  
7. `스케줄러`가 어떤 노드에 파드를 배치할지 결정, `스케줄러`가 `파드 API`를 호출해 `etcd` 업데이트(어떤 노드에 배치할지)  
8. `파드 API`를 `watch`(감시)하고 있는 노드의 `kubelet`이 변화를 감지  
9. `kubelet`이 `컨테이너 런타임`에 포드 작성 지시  
10. `컨테이너` 생성  


이벤트 체인은 이 과정을 지속적으로 루프한다.  

실제 디플로이먼트를 `apply`하고 일련의 이벤트 체인 과정을 확인하고 싶다면 아래 명령 사용  

```
$ kubectl get events -w
```

```yaml
# nginx-deployment.yaml
# 기본항목
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
# 디플로이먼트 스팩
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-pod # 템플릿 검색조건
  # 파드 템플릿
  template:
    metadata:
      labels:
        app: nginx-pod
    spec:
      containers:
        - name: nginx
          image: nginx:1.15 # 컨테이너 이미지
          ports:
            - containerPort: 80
```
위의 디플로이먼트 매니페스트를 `apply` 하고 이벤트 체인에서 출력되는 메세지를확인  

```
$ kubectl get events -w
LAST SEEN   TYPE     REASON              OBJECT                        MESSAGE
0s          Normal   ScalingReplicaSet   deployment/nginx-deployment   Scaled up replica set nginx-deployment-f75fb748c to 3
0s          Normal   SuccessfulCreate    replicaset/nginx-deployment-f75fb748c   Created pod: nginx-deployment-f75fb748c-hq556
0s          Normal   SuccessfulCreate    replicaset/nginx-deployment-f75fb748c   Created pod: nginx-deployment-f75fb748c-j2sh9
1s          Normal   SuccessfulCreate    replicaset/nginx-deployment-f75fb748c   Created pod: nginx-deployment-f75fb748c-wbpzp
<unknown>   Normal   Scheduled           pod/nginx-deployment-f75fb748c-j2sh9    Successfully assigned default/nginx-deployment-f75fb748c-j2sh9 to minikube
<unknown>   Normal   Scheduled           pod/nginx-deployment-f75fb748c-hq556    Successfully assigned default/nginx-deployment-f75fb748c-hq556 to minikube
<unknown>   Normal   Scheduled           pod/nginx-deployment-f75fb748c-wbpzp    Successfully assigned default/nginx-deployment-f75fb748c-wbpzp to minikube
0s          Normal   Pulling             pod/nginx-deployment-f75fb748c-hq556    Pulling image "nginx:1.15"
0s          Normal   Pulling             pod/nginx-deployment-f75fb748c-j2sh9    Pulling image "nginx:1.15"
0s          Normal   Pulling             pod/nginx-deployment-f75fb748c-wbpzp    Pulling image "nginx:1.15"
0s          Normal   Pulled              pod/nginx-deployment-f75fb748c-hq556    Successfully pulled image "nginx:1.15"
0s          Normal   Created             pod/nginx-deployment-f75fb748c-hq556    Created container nginx
0s          Normal   Started             pod/nginx-deployment-f75fb748c-hq556    Started container nginx
0s          Normal   Pulled              pod/nginx-deployment-f75fb748c-j2sh9    Successfully pulled image "nginx:1.15"
0s          Normal   Created             pod/nginx-deployment-f75fb748c-j2sh9    Created container nginx
0s          Normal   Started             pod/nginx-deployment-f75fb748c-j2sh9    Started container nginx
0s          Normal   Pulled              pod/nginx-deployment-f75fb748c-wbpzp    Successfully pulled image "nginx:1.15"
0s          Normal   Created             pod/nginx-deployment-f75fb748c-wbpzp    Created container nginx
0s          Normal   Started             pod/nginx-deployment-f75fb748c-wbpzp    Started container nginx
```

`API Server` 에선 매니페스트 파일로 `etcd` 에 업데이트만 할뿐 이를 쿠버네티스 컨트롤러가 각각 감시하며 별도로 움직인다.  

## kubnet

`kubnet` 은 쿠버네티스 표준 네트워크 플러그인이다. 

![kube5](/assets/2020/kube5.png)  

노드간 연결은 `10.100.0.0/16` 네트워크로 연결된다.  

노드안의 포드간의 네트워크는 클러스터 전체에서 검사 후 결정된다.  
그리고 중복되지 않는 파드 `CIDR`을 할당한다.

> 사이더(`Classless Inter-Domain Routing`): `CIDR`는 클래스 없는 도메인 간 라우팅 기법으로 1993년 도입되기 시작한, 최신의 IP 주소 할당 방법이다. https://ko.wikipedia.org/wiki/사이더_(네트워킹)

위에선 각각의 노드에 `10.1.1.0/24`, `10.1.1.1/24`를 할당했다.  

포드간의 통신지원을 위해 특정 포드에 접근할 수 있는 노드의 인터페이스를 사용자 정의 루트에 기록한다.  
쿠버네티스 내부에서 자동으로 이런 네트워크 구조와 라우팅 테이블을 유지하는 것을 기억해두자.  

# 쿠버네티스 구축  

`minikube` 툴을 사용해 간단한 학습용 클러스터를 구축해서 사용중이지만 실제 클러스터 구축에는 아래와 같은 과정을 진행해야한다.  

1. 노드간 네트워크 작성  
2. 마스터 서버 작성  
3. 마스터 서버 로드밸런서 작성  
4. 노드 서버 작성  
5. 포드간 네트워크 작성  
6. 증명서 작성과 배포  
7. `etcd` 설정 파일의 작성과 배포  
8. `etcd` 시작  
9. 쿠버네티스 설정 파일 작성과 배포  
10. 쿠버네티스 컴포넌트 배포  
11. 쿠버네티스 컴포넌트 실행  
12. 쿠버네티스 애드온 컴포넌트 작성  

다행이 이 모든 과정을 자동화 해주는 툴이 있다.  

> 만약 위의 과정을 힘들게 수동으로 처리하고 싶다면 아래 URL 참고
> https://github.com/kelseyhightower/kubernetes-the-hard-way


## 마스터 가용성  

운영중인 서비스의 가용성을 늘리려면 노드를 확보하고 파드를 늘리면 된다.  

쿠버네티스 자체의 가용성을 늘리려면 아래 그림처럼 **컨트롤 플레인**을 다중화 하여 가용성을 확보해야한다.  

![kube6](/assets/2020/kube6.png)  

`etcd` 는 클러스터로 구축하여 서로같의 데이터를 항시 동기화 하고  

`API Server` 서버는 로드밸런서를 사용해 엑세스를 분산시킨다.  

`컨트롤러 매니저`와 `스케줄러`는 **액티브/스탠바이형**을 가지며 액티브한 마스터 컴포넌트의 장애에 대비한다. 서로간의 경합을 피하기 위해 동시간대에 하나씩의 컴포넌트만 동작한다.  

액티브한 컴포넌트는 기본값인 2초마다 갱신시간을 기록하며 
`kube-system` 네임 스페이스의 `endpoints`인 `kube-controller-manager` 에서 확인 가능하다.  

`renewTime` 속성 확인  

```
$ kubectl get endpoints kube-controller-manager -n kube-system -o yaml
apiVersion: v1
kind: Endpoints
metadata:
  annotations:
    control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"minikube_2a1b1ca1-403a-45e1-b4b8-c50afb0e14a1","leaseDurationSeconds":15,"acquireTime":"2020-04-29T16:36:09Z","renewTime":"2020-05-05T11:32:38Z","leaderTransitions":3}'
  creationTimestamp: "2020-04-28T08:17:42Z"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:control-plane.alpha.kubernetes.io/leader: {}
    manager: kube-controller-manager
    operation: Update
    time: "2020-05-05T11:32:38Z"
  name: kube-controller-manager
  namespace: kube-system
  resourceVersion: "174543"
  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-controller-manager
  uid: c38faf14-ceb3-4e54-91fd-fa730b1d58a9
```

> 컨트롤 플레인의 노드(마스터 노드)의 개수는 홀수로 하는것이 좋다. etcd 클러스터에서 노드간의 투표를 통해 데이터 동기화를 진행하기에 항상 항상 과반수가 나오는 홀수를 권장하며 3 ~ 7개 까지의 노드수가 효율적이다.  

## 노드 가용성  

일반 노드에선 컨트롤 플레인에서 고려할 각종 문제점이 없기에  
가용성, 다중화가 필요하다면 노드(서버)를 추가확보하기만 하면 된다.  

단 노드 다운시 해당 노드에 존재하던 파드들이 다른 노드에 배치되기에 리소스를 확인하며 노드확보할 필요가 있다.  
노드 2개 운영시 하나의 노드가 다운될 경우 다른 하나의 노드에 부하가 집중됨으로 노드는 3개 이상으로 구성하는것이 전형적인 구조이다.  

### 노드 인프라스트럭처  

가장큰 리소스인 노드부터 가장작은 파드, 각종 컴포넌트들의 다중화를 진행하였어도  
**폭발반경(Blast Radius)**을 계산하지 않는다면 물리적 장애 발생시 대처가 불가능하다.  

폭발반경의 범위는 아래와 같다.  

1. 물리서버  
2. 랙  
3. 데이터 센터  
4. 지역  

만약 하나의 물리서버에 가상머신을 사용해 모든 서버를 올리게 되면 해당 물리서버 다운시 모든 서비스가 중단된다.  
만약 하나의 랙에 모든 서비스 운영 물리서버를 설치한다면 해당 랙의 전력이나 네트워크 다운시 모든 서비스가 중단된다.  
데이터 센터나 지역도 마찬가지이다. 재난 발생시에 전력, 네트워크가 차단될 경우 모든 서비스가 중단된다.  

폭발반경을 의식하며 동일한 종류의 서버(노드, 컨트롤 플레인), 가상머신을 분리 배치해야한다.  

데이터센터 폭발반경을 의식해 쿠버네티스 리소스를 분산배치할 경우 동기화 스르풋, 타임아웃이 될 위험이 발생한다.  
컨트롤 플레인의 경우 특히 더 민감한데 하트비트 100밀리초, 리더선출 1000밀리초를 기본값으로 사용한다. 

애저의 경우 한국 중부, 남부지역의 지연시간은 10밀리초 정도라한다.  
전용 네트워크 백본을 통해 연결되기에 이보다 더 빨라질순 없다.  

만약 목표를 10밀리초 이하로 잡아야 한다면 별도에 지역에 클러스터 하나를 구축하는것이 아닌
하나의 지역마다 클러스터 하나를 구축해야 한다.  

## 업데이트, 업그레이드  

쿠버네티스 클러스터 운영시 2가지의 버전업이 필요하다.  

1. 쿠버네티스 컴포넌드 버전업  
2. 쿠버네시트 서버 버전업  

쿠버네티스는 마이너는 3개월 간격으로 버전이 릴리즈 되고 있으며 단순 버그 패치는 한달에 한두번 릴리즈 되고 있다.  

### Cordon, Uncordon, Drain


업데이트시에 노드의 재부팅이 빈번히 일어남으로 쿠버네티스 스케줄링에서 제외해야 한다.  
이때 `Cordon`, `Uncordon` 명령을 사용한다.

> `Cordon`: 폐쇄하다  

다음과 같은 간단한 `Deployment`를 apply  

```yaml
# nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
```

```
$ kubectl apply -f nginx.yaml
$ kubectl get pod --output=wide
NAME                    READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
nginx-f89759699-5pqrm   1/1     Running   0          96s   172.18.0.2   minikube-m03   <none>           <none>
nginx-f89759699-7pmmz   1/1     Running   0          96s   172.18.0.2   minikube-m02   <none>           <none>
nginx-f89759699-wxjtx   1/1     Running   0          96s   172.18.0.3   minikube-m03   <none>           <none>

$ kubectl cordon minikube-m02
node/minikube-m02 cordoned

$ kubectl get node
NAME           STATUS                     ROLES    AGE    VERSION
minikube       Ready                      master   143m   v1.18.0
minikube-m02   Ready,SchedulingDisabled   <none>   141m   v1.18.0
minikube-m03   Ready                      <none>   11m    v1.18.0
```

`minikube-m02` 노드를 `cordon` 명령을 통해 스케줄링에서 제외한다.  

`STATUS` 에 `SchedulingDisabled` 상태가 추가된 것을 확인  

이 상태에서 `replicas` 를 6으로 변경한다.  

```
$ kubectl get pod --output=wide
NAME                    READY   STATUS    RESTARTS   AGE     IP           NODE           NOMINATED NODE   READINESS GATES
nginx-f89759699-5pqrm   1/1     Running   0          3h25m   172.18.0.2   minikube-m03   <none>           <none>
nginx-f89759699-7pmmz   1/1     Running   0          3h25m   172.18.0.2   minikube-m02   <none>           <none>
nginx-f89759699-fnfst   1/1     Running   0          23s     172.18.0.5   minikube-m03   <none>           <none>
nginx-f89759699-mcpj2   1/1     Running   0          23s     172.18.0.6   minikube-m03   <none>           <none>
nginx-f89759699-tmhz2   1/1     Running   0          23s     172.18.0.4   minikube-m03   <none>           <none>
nginx-f89759699-wxjtx   1/1     Running   0          3h25m   172.18.0.3   minikube-m03   <none>           <none>
```

`minikube-m02`에는 추가되지 않고 `minikube-m03`에만 파드가 추가생성되었다.   

`minikube-m02`를 `Uncordon` 명령으로 스케줄링 대상으로 복원

```
$ kubectl uncordon minikube-m02
node/minikube-m02 uncordoned

$ kubectl get node
NAME           STATUS   ROLES    AGE     VERSION
minikube       Ready    master   5h48m   v1.18.0
minikube-m02   Ready    <none>   5h46m   v1.18.0
minikube-m03   Ready    <none>   3h36m   v1.18.0
```

`Drain`은 `Cordon` 움직임에 포드의 삭제, 재작성을 더한것이다.  

```
$ kubectl drain minikube-m03
node/minikube-m03 cordoned
error: unable to drain node "minikube-m03", aborting command...

There are pending nodes to be drained:
 minikube-m03
error: cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kindnet-v7qmx, kube-system/kube-proxy-b6r9k
```

노드 전용으로 움직이는 데몬셋은 다른 노드로 옮기수 없기에 오류가 발생한다.  

```
$ kubectl drain minikube-m03 --ignore-daemonsets
node/minikube-m03 already cordoned
WARNING: ignoring DaemonSet-managed Pods: kube-system/kindnet-v7qmx, kube-system/kube-proxy-b6r9k
evicting pod default/nginx-f89759699-fnfst
evicting pod default/nginx-f89759699-5pqrm
evicting pod default/nginx-f89759699-mcpj2
evicting pod default/nginx-f89759699-tmhz2
evicting pod default/nginx-f89759699-wxjtx
pod/nginx-f89759699-mcpj2 evicted
pod/nginx-f89759699-wxjtx evicted
pod/nginx-f89759699-fnfst evicted
pod/nginx-f89759699-tmhz2 evicted
pod/nginx-f89759699-5pqrm evicted
node/minikube-m03 evicted

$ kubectl get node
NAME           STATUS                     ROLES    AGE     VERSION
minikube       Ready                      master   5h54m   v1.18.0
minikube-m02   Ready                      <none>   5h52m   v1.18.0
minikube-m03   Ready,SchedulingDisabled   <none>   3h42m   v1.18.0

$ kubectl get pod --output=wide
NAME                    READY   STATUS    RESTARTS   AGE     IP           NODE           NOMINATED NODE   READINESS GATES
nginx-f89759699-5nh2s   1/1     Running   0          91s     172.18.0.5   minikube-m02   <none>           <none>
nginx-f89759699-7pmmz   1/1     Running   0          3h33m   172.18.0.2   minikube-m02   <none>           <none>
nginx-f89759699-9x2gq   1/1     Running   0          91s     172.18.0.6   minikube-m02   <none>           <none>
nginx-f89759699-jxdbq   1/1     Running   0          91s     172.18.0.3   minikube-m02   <none>           <none>
nginx-f89759699-kdtqs   1/1     Running   0          91s     172.18.0.4   minikube-m02   <none>           <none>
nginx-f89759699-pp4kh   1/1     Running   0          91s     172.18.0.7   minikube-m02   <none>           <none>
```

> `evicted`: 퇴거

`drain` 설정한 노드의 파드는 모두 다른 노드에 재작성 되고 스케줄링에서 제외된다.  

<!-- ### Kured (Kubernetes Rebooot Daemon)

노드 재시작시 Cordon, Drain 의 명령을 통해 수동으로 스케줄링에서 제외시킬 수 있다.  
`Kured` 을 사용하면 자동으로 재시작이 필요한 노드를 감지하고 클러스터 전체에 대한 영향을 고려해 reboot 한다.   -->
















