---
title:  "쿠버네티스 - 개요!"

read_time: false
share: false
author_profile: false
# classes: wide

categories:
  - docker
  - kubernetes

tags: kubernetes

toc: true
toc_sticky: true

---


# 쿠버네티스

구글에서 스타트한 오픈소스로 구성된 컨테이너 오케스트레이션 툴.  

컨테이너 오케스트레이션 툴은 쿠버네티스 외에도 도커 스웜, 아파치 Mesos 등이 있다.  

# minikube 설치

쿠버네티스 실습용으로 실제 클러스터용 PC 를 여러대 구매하여 구축하면 좋겠지만   
`minikube` 라는 툴로도 가상으로 로컬피시에 환경 구축이 가능하다.  

가상환경은 기본적으로 `docker` 를 사용하도록 설정한다.  

```
$ brew install minikube
$ minikube start --driver=docker
😄  Darwin 10.15.4 위의 minikube v1.9.2
✨  유저 환경 설정 정보에 기반하여 docker 드라이버를 사용하는 중
👍  Starting control plane node m01 in cluster minikube
🚜  Pulling base image ...
💾  Downloading Kubernetes v1.18.0 preload ...
    > preloaded-images-k8s-v2-v1.18.0-docker-overlay2-amd64.tar.lz4: 542.91 MiB

🔥  docker container (CPUs=2, Memory=1989MB, Disk=<no value>MB) 에 쿠버네티스를 설치하는 중 ...
🐳  쿠버네티스 v1.18.0 을 Docker 19.03.2 런타임으로 설치하는 중
    ▪ kubeadm.pod-network-cidr=10.244.0.0/16
🌟  애드온을 활성화하는 중: default-storageclass, storage-provisioner
🏄  끝났습니다! 이제 kubectl 이 "minikube" 를 사용할 수 있도록 설정되었습니다
$ minikube config set driver docker // docker 를 기본 가상드라이버로 설정  
```

실행된 `minikube` 상태 조회  

```
$ minikube status
m01
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```

멈췄다 재실행 

```
$ minikube stop
$ minikube start

😄  Darwin 10.15.4 위의 minikube v1.9.2
✨  기존 프로필에 기반하여 docker 드라이버를 사용하는 중
👍  Starting control plane node m01 in cluster minikube
🚜  Pulling base image ...
🔄  Restarting existing docker container for "minikube" ...
🐳  쿠버네티스 v1.18.0 을 Docker 19.03.2 런타임으로 설치하는 중
    ▪ kubeadm.pod-network-cidr=10.244.0.0/16
E0415 14:15:03.709410   31540 kubeadm.go:331] Overriding stale ClientConfig host https://127.0.0.1:32768 with https://127.0.0.1:32771
🌟  애드온을 활성화하는 중: default-storageclass, storage-provisioner
🏄  끝났습니다! 이제 kubectl 이 "minikube" 를 사용할 수 있도록 설정되었습니다
```

미니쿠버네티스는 도커 컨테이너에서 돌아간다.  
> 드디어 가상으로 만들어진 클러스터가 구축되었다.  

```
$ docker ps
CONTAINER ID        IMAGE                                COMMAND                  CREATED             STATUS              PORTS                                                                           NAMES
2f61e951c809        gcr.io/k8s-minikube/kicbase:v0.0.8   "/usr/local/bin/entr…"   13 minutes ago      Up 10 minutes       127.0.0.1:32773->22/tcp, 127.0.0.1:32772->2376/tcp, 127.0.0.1:32771->8443/tcp   minikube
```

`kubectl` 명령을 통해 로컬에 설치된 클러스터를 조작 가능하다.  

```
$ kubectl get node -o=wide
NAME       STATUS   ROLES    AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION     CONTAINER-RUNTIME
minikube   Ready    master   4m25s   v1.18.0   172.17.0.2    <none>        Ubuntu 19.10   4.19.76-linuxkit   docker://19.3.2
```

`k8s.gcr.io/echoserver:1.10` 이미지를 가져와 `hello-minikube` 라는 이름으로 배포  

```
$ kubectl create deployment hello-minikube --image=k8s.gcr.io/echoserver:1.10
deployment.apps/hello-minikube created

$ kubectl expose deployment hello-minikube --type=NodePort --port=8080
service/hello-minikube exposed

$ kubectl get pod
NAME                              READY   STATUS    RESTARTS   AGE
hello-minikube-64b64df8c9-xrhc2   1/1     Running   0          2m10s
```

서비스 상세보기  

```
$ minikube service hello-minikube --url

🏃  Starting tunnel for service hello-minikube.
|-----------|----------------|-------------|------------------------|
| NAMESPACE |      NAME      | TARGET PORT |          URL           |
|-----------|----------------|-------------|------------------------|
| default   | hello-minikube |             | http://127.0.0.1:51402 |
|-----------|----------------|-------------|------------------------|
http://127.0.0.1:51402
❗  Because you are using docker driver on Mac, the terminal needs to be open to run it.
```

위의 url 로 들어가면 아래 페이지가 출력된다.  

```
Hostname: hello-minikube-64b64df8c9-xrhc2

Pod Information:
	-no pod information available-

Server values:
	server_version=nginx: 1.13.3 - lua: 10008

Request Information:
	client_address=172.18.0.1
	method=GET
	real path=/
	query=
	request_version=1.1
	request_scheme=http
	request_uri=http://127.0.0.1:8080/

Request Headers:
	accept=text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
	accept-encoding=gzip, deflate, br
	accept-language=ko,en-US;q=0.9,en;q=0.8
	connection=keep-alive
	host=127.0.0.1:51402
	sec-fetch-dest=document
	sec-fetch-mode=navigate
	sec-fetch-site=none
	sec-fetch-user=?1
	upgrade-insecure-requests=1
	user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36

Request Body:
	-no body in request-
```

```
$ kubectl delete services hello-minikube
service "hello-minikube" deleted

$ kubectl delete deployment hello-minikube
deployment.apps "hello-minikube" deleted
```

## 쿠버네티스 버전

```
$ kubectl version --output yaml
clientVersion:
  buildDate: "2020-04-10T21:53:51Z"
  compiler: gc
  gitCommit: 7879fc12a63337efff607952a323df90cdc7a335
  gitTreeState: clean
  gitVersion: v1.18.1
  goVersion: go1.14.2
  major: "1"
  minor: "18"
  platform: darwin/amd64
serverVersion:
  buildDate: "2020-03-25T14:50:46Z"
  compiler: gc
  gitCommit: 9e991415386e4cf155a24b1da15becaa390438d8
  gitTreeState: clean
  gitVersion: v1.18.0
  goVersion: go1.13.8
  major: "1"
  minor: "18"
  platform: linux/amd64
```

클라이언트와 서버의 버전이 모두 `v1.18.0` 임을 확인 가능하다.  

# 쿠버네티스 아키텍처

## 마스터

쿠버네티스 클러스터 전체를 관리하는 역할   
여러대의 클러스터 노드의 리소스 상황 파악, 컨테이너를 가동시킬 노드를 선택  

`etcd` 라는 분산 `Key-value store` (KVS) 를 사용해 클러스터 구성정보를 관리  

> `/etc` 디렉토리를 `distribute` 하는 뜻을 담은 단어. 레드헷에서 설정파일을 서버간 공유하기 위해 만든 툴을 쿠버네티스에서 승계한것.  

## 노드

> https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/explore/explore-intro/

컨테이너가 작동되는 서버, 여러대의 노드를 준비해 클러스터를 구성,  
노드는 클라우드 서비스 회사의 가상 머신 혹은 물리 머신이 노드역할을 한다.  

해당 노드안에서 여러대의 컨테이너(일반적으로 도커)가 동작  


# 쿠버네티스 컴포넌트

> https://kubernetes.io/ko/docs/concepts/overview/components/

마스터와 노드는 내부에서 각종 동작을 하는 컴포넌트들이 존재한다.

![kube1](/assets/2020/kube1.png)  


## 마스터 컴포넌트

**API Server** - 쿠버의 리소스 정보를 관리하기 위한 프론트 엔드 Rest API 서버, 각 컴포넌트로부터 정보를 받아 etcd 에 저장하는 역할, etcd의 정보를 다른 컴포넌트에 전달하는 역할.  
`kubectl` 명령을 통해 조작 가능하다.  

**스케줄러** - 파드를 어느 노드에서 작동시킬지를 제어하는 백앤드 컴포넌트, `API Server` 와 통신하며 클러스터 상태를 확인, 빈공간의 노드에 파드를 할당 및 실행하는 스케줄링을 처리한다.  

**컨트롤러 매니저** - 클러스터의 상태를 감시, 항상 정상상태를 유지시키는 백앤드 컴포넌트

**데이터 스토어(etcd)** - 클러스터의 구성을 유지하는 분산 key-value store, API Server 가 이를 참조해 각 컴포넌트가 동작할 수 있도록 도와줌, 데이터 스토어는 마스터 서버에서 분리 가능  

## 노드 컴포넌트

**kubelet** - 노드 내부에선 `kubelet` 이라는 에이전트가 움직이며 컨테이너를 실행한다. `kubelet` 은 노드의 `status` 를 정기적으로 감시하며 이를 `API Server` 로 전송한다.  

**kube-proxy** - 다양한 중계 및 변환을 수행하는 네트워크 프록시  

## kubectl 

마스터 컴포넌트 중 하나인 `API Server` 와 통신하기 위해 `kubectl` 명령을 사용한다.   
`kubectl` 과 `API Server`가 어떻게 연결되어 있는지 알아보자.  

```
$ ls ~/.kube
cache      config     http-cache
```

```yaml
clusters:
- cluster:
    certificate-authority: /Users/gojiyong/.minikube/ca.crt
    server: https://127.0.0.1:32768
  name: minikube 
# kubectl 명령 실행시 사용할 클러스터 정보

contexts:
- context:
    cluster: minikube
    user: minikube
  name: minikube
current-context: minikube
kind: Config
preferences: {}
# 클러스터 사용자 정보 context, 

users:
- name: minikube
  user:
    client-certificate: /Users/gojiyong/.minikube/profiles/minikube/client.crt
	client-key: /Users/gojiyong/.minikube/profiles/minikube/client.key
# 엑세스 하는 사용자 정보 - 클러스터 엑세스를 위한 인증 키 등 설정  
```


# 쿠버네티스 리소스

## 파드(Pod)

> https://kubernetes.io/ko/docs/concepts/workloads/pods/pod-overview/

쿠버에선 여러개의 컨테이너를 모아 파드로 관리한다.  

![kube2](/assets/2020/kube2.png){: .shadow}{: width="400"} 

파드 내부에서 웹서버용, 파일서버용, 프록시 서버용 도커 컨테이너 여러개를 모아 관리할 수 있다.  
쿠버에선 이 파드가 앱 디플로이 단위가 되며 파드 단위로 컨테이너 작성, 시작, 정지, 삭제 등의 조작을 진행한다.  

파드는 항상 하나의 노드에 배치되며 파드가 쪼개질 순 없다.  

따라서 파드 내부에서 가상 네트워크 인터페이스 카드(**사설IP**)를 각 컨테이너에게 발급하며 서로 같은 네트워크 안에 있음으로 `localhost` 를 통해 통신 가능하다.  



## 리플리카 셋(Replica Set)

> https://kubernetes.io/ko/docs/concepts/workloads/controllers/replicaset/

클러스터 안에 지정된 수의 파드를 일정하게 유지하며 장애대응 및 자동 실행하는 역할.  
클러스터 안에서 가동되는 파드 수를 **리플리카 수** 라 한다.  

## 디플로이먼트(Deployment)

> https://kubernetes.io/ko/docs/concepts/workloads/controllers/deployment/

애플리케이션 배포 버전 단위를 관리하는 리소스.  

파드안의 컨테이너를 버전업 하고 싶을 때 시스템을 정지시키지 않고 버전업(롤링업데이트), 롤백 가능

## 데몬 셋(Daemon Set)

> https://kubernetes.io/ko/docs/concepts/workloads/controllers/daemonset/

스케줄러가 어떤 노드에서 동작할지는 마스터 노드에서 자동으로 결정된다.  

하지만 특정 파드(로그콜렉터, 감시에이전트 등)는 클러스터에서 반드시 하나씩 작동시키고 싶은 경우가 있는데 이때 데몬셋을 사용한다.  

리플리카 셋과 비교해 좀더 엄격하게 관리하고 싶다면 데몬셋을 사용  
리플리카 셋과 다르게 실행중인 파드 수 를 결정할 수 도 없다.  

> kube-proxy 또한 데몬 셋을 사용해 가동된다.  

## 스테이트풀 셋(Stateful Set)

> https://kubernetes.io/ko/docs/concepts/workloads/controllers/statefulset/


컨테이너는 stateless 로 실행된다, 어떤 노드에서 어떤 IP 를 가지고 실행될지 모른다는 뜻이다.  

데이터 베이스와 같은 고정된 상태(Stateful) 을 필욜로 할 경우도 있는데 이때 **스테이트풀 셋** 를 사용한다.

안정된, 고정된, 지속성을 보증한다.  

# 쿠버네티스 네트워크 관리

클러스터 안의 파드에 대해 클러스터 내부에서, 외부에서 엑세스 하기 위한 리소스가 `Service`, `Ingress` 이다.

> Ingress: 입장권

## Service

> https://kubernetes.io/ko/docs/concepts/services-networking/service/

클러스터 안에서 실행된 파드에 대해 엑세스 할 때 `Service` 를 정의한다.  
`Service` 에 의해 할당되는 IP 주소에는 `Cluster IP` `External IP` 가 있다.  

`Cluster IP` - 클러스터 내부에서 파드끼리 통신하기 윈한 IP 
`External IP` - 외부에 공개하는 IP

클러스터 내부 파드간에는 노드상의 Proxy 데몬이 송수신 처리를 해준다.  

## Ingress 

> https://kubernetes.io/ko/docs/concepts/services-networking/ingress/

클러스터 내의 서비스에 대한 외부 접근을 관리하는 API 오브젝트, 일반적으로 HTTP를 관리한다.  

# 어플리케이션 설정정보 관리

## Config Map

컨테이너에 할당될 어플리케이션의 설정정보, 구성파일, 명령인수, 포트번호, 고유식별 번호 등을 파드에서 참조할 수 있도록 해주는 데이터, `Key-Value` 형식의 파일형태의 데이터.  

볼륨 마운트를 통해 각 컨테이너에서 공통 설정저보로 사용될 수 있다.  

## Secrets

컨피그 맵과 같이 구성정보를 어플리케이션에 전달하기 위한 데이터, `DB password`, `OAuth` 토큰과 같은 비밀 정보를 주로 관리한다.  

암호화 되어 `etcd` 에서 관리됨.  

# 배치 잡 관리

웹, DB 서버와 같은 상주 서비스는 파드를 통해 항시 관리되지만  
기계학습, 배치처리는 `Job`, `CronJob` 을 통해 실행되고 정지(실행완료)된다.  

## Job

`Job`은 하나 이상의 파드에서 배치처리를 하기 위한 리소스.  
DB 마이크레이션같은 한번의 실행으로 끝나는 것에 이용된다.  

`Job` 의 실행 오류, 예외 발생시 `Job` 컨트롤러가 성공할 때까지 파드를 새로 생성해 실행시킨다.

## CronJob

`CronJob` 은 정해진 시간에 `Job` 을 수행하기 위한 리소스.  
백업, 메일 송신 등과 같은 배치처리에 사용된다.  


# 매니페스트 파일(Manifest file)

> Manifest: 선언서

클러스터 내부에서 움직이는 컨테이너, 네트워크, 잡 등의 쿠버네티스 리소스를 매니페스트 파일을 통해 관리한다.   
`yaml`, `json` 형식의 파일로 구성된다.   

```yaml
# webserver.yaml
apiVersion: apps/v1 # api 버전 정보 - 호출할 api 버전 지정, alpha(v1alpha1 등), beta(v2beta3 등), 안정판(v1) 
kind: ReplicaSet # 쿠버 리소스 종류 - Pod, ReplicaSet, Service, ConfigMap, Job 등등
metadata:
  name: webserver # 리소스 이름 - kubectl 명령으로 조작할 때 사용하는 이름
spec: # 리소스의 상세 정보 - kind 속성에 따라 사용할 수 있는 속성이 달라짐, 아래는 ReplicaSet 에서 사용 가능한 속성들  
  replicas: 10
  selector:
    matchLabels:
      app: webfront
  template:
    metadata:
      labels:
        app: webfront
    spec:
      containers:
      - image: nginx
        name: webfront-container
        ports:
          - containerPort: 80
```

매니페스트 파일을 사용해 쿠버네티스 리소스 생성  

```
$ kubectl apply -f webserver.yaml
replicaset.apps/webserver created

$ kubectl get pod
NAME              READY   STATUS              RESTARTS   AGE
webserver-2b49v   1/1     Running             0          46s
webserver-2k8lb   0/1     ContainerCreating   0          46s
webserver-9rwg5   1/1     Running             0          46s
webserver-clkzm   1/1     Running             0          46s
webserver-dp4pq   0/1     ContainerCreating   0          46s
webserver-fjznl   1/1     Running             0          46s
webserver-l2c96   0/1     ContainerCreating   0          46s
webserver-qm9bp   1/1     Running             0          46s
webserver-qxxbl   1/1     Running             0          46s
webserver-vb5jc   1/1     Running             0          46s
```

`pod` 10개가 생성되었다.  

매니페스트 파일의 정보는 `etcd` 에서 관리한다.  
`kuberctl` 명령으로 매니페스트 파일 업데이트가 가능하며 업데이트 버전 정보가 추가 기록된다.   

삭제 명령  
```
$ kubectl delete -f webserver.yaml
replicaset.apps "webserver" deleted
```

## kind  

> https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/kubernetes-objects/

`kind` 속성에는 메니페스트에 설정할 쿠버네티스 리소스 종류를 기술한다.  

* 애플리케이션의 실행 - `Pod`, `ReplicaSet`, `Deployment`  
* 네트워크의 관리 - `Service`, `Ingress`  
* 애플리케이션 설정 정보의 관리 - `ConfigMap`, `Secrets`
* 배치잡의 관리 - `Job`, `CronJob`  


## labels

> https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/labels/


쿠버에선 수월한 리소스 관리를 위해 `label` 를 사용한다.  

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod-a
  labels: # key-value 형식으로 구성
    env: test # 
    app: photo-view
spec:
  containers:
  - image: nginx
	name: photoview-container
---
apiVersion: v1 # - 를 사용해 하나의 파일에 2개의 리소스 정보 입력 가능
kind: Pod
metadata:
  name: nginx-pod-b
  labels:
    env: test
    app: imagetrain
spec:
  containers:
  - image: nginx
    name: photoview-container
```

```
$ kubectl apply -f Label/label-pod.yaml
pod/nginx-pod-a created
pod/nginx-pod-b created

$ kubectl get pod --show-labels
NAME              READY   STATUS    RESTARTS   AGE   LABELS
nginx-pod-a       1/1     Running   0          24s   app=photo-view,env=test
nginx-pod-b       1/1     Running   0          24s   app=imagetrain,env=test
```

매니페스트 파일 내부 리소스 `label` 을 수정해서 다시 `apply`,  
`imagetrain -> predictoin` 으로 수정

```
$ kubectl apply -f Label/label-pod.yaml
pod/nginx-pod-a unchanged
pod/nginx-pod-b configured

$ kubectl get pod --show-labels
NAME              READY   STATUS    RESTARTS   AGE    LABELS
nginx-pod-a       1/1     Running   0          6m3s   app=photo-view,env=test
nginx-pod-b       1/1     Running   0          6m3s   app=predictoin,env=test
```

### Label Selector  

```
$ kubectl get pod -l app=photo-view,env=test
NAME          READY   STATUS    RESTARTS   AGE
nginx-pod-a   1/1     Running   0          7m13s
```

|연산자|설명|
|---|---|
`key=value` | `key` 값이 `value` 일 경우
`key!=value` | `key` 값이 `value` 아닐 경우
`'key in (...value)'` | `key` 값이 `value` 에 포함 될경우
`'key notin (...value)'` | `key` 값이 `value` 에 포함되지 않을 경우
`key` | `key` 값이 존재할 경우
`!key` | `key` 값이 존재하지 않을 경우

> `in`, `notin` 연산은 홀따옴표로 묶어주어야 한다.  
콤마로 `AND` 연산은 사용 가능하지만 `OR` 연산은 사용 불가능하다.  

삭제명령  
```
$ kubectl delete -f Label/label-pod.yaml
pod "nginx-pod-a" deleted
pod "nginx-pod-b" deleted
```

## 네임 스페이스

> https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/namespaces/

`Pod` 를 포함한 각종 쿠버네티스 리소스를 그룹화, 다른 그룹끼리는 분리화 하는 기능을 지원한다.  

네임스페이스만 다르면 동일한 리소스 네임을 사용할 수 있다.   
> 단 노드는 동일한 리소스명 사용 불가능  

```
$ kubectl get namespace
NAME              STATUS   AGE
default           Active   6d4h
kube-node-lease   Active   6d4h
kube-public       Active   6d4h
kube-system       Active   6d4h
```

* `default`: 기본값, 네임스페이스 지정x  
* `kube-public`: 모든 사용자가 이용할 수 있는 `ConfigMap` 같은 리소스  
* `kube-system`: 쿠버 클러스터가 내부에서 사용하는 리소스  

`kube-system` 네임스페이스 내부에서 돌아가는 pod 목록 확인  
```
$ kubectl get pod --namespace kube-system --show-labels
NAME                               READY   STATUS    RESTARTS   AGE    LABELS
coredns-66bff467f8-njwnv           1/1     Running   3          6d4h   k8s-app=kube-dns,pod-template-hash=66bff467f8
coredns-66bff467f8-nt4vd           1/1     Running   4          6d4h   k8s-app=kube-dns,pod-template-hash=66bff467f8
etcd-minikube                      1/1     Running   3          6d4h   component=etcd,tier=control-plane
kindnet-f5f4h                      1/1     Running   4          6d4h   app=kindnet,controller-revision-hash=5c5d549dd7,k8s-app=kindnet,pod-template-generation=1,tier=node
kube-apiserver-minikube            1/1     Running   3          6d4h   component=kube-apiserver,tier=control-plane
kube-controller-manager-minikube   1/1     Running   3          6d4h   component=kube-controller-manager,tier=control-plane
kube-proxy-9dj5s                   1/1     Running   3          6d4h   controller-revision-hash=c8bb659c5,k8s-app=kube-proxy,pod-template-generation=1
kube-scheduler-minikube            1/1     Running   3          6d4h   component=kube-scheduler,tier=control-plane
storage-provisioner                1/1     Running   5          6d4h   addonmanager.kubernetes.io/mode=Reconcile,integration-test=storage-provisioner
```

지금까지 별도의 `namespace` 를 지정해서 `pod` 를 생성한적이 없기때문에 모두 `default` 네임스페이스에 포함되어 있을것.  

### 네임스페이스 생성  

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: trade-system
```

`kind` 속성을 `Namespace` 로 지정 후 생성  

```
$ kubectl create -f Namespace/namespace.yaml
namespace/trade-system created

$ kubectl get namespaces
NAME              STATUS   AGE
default           Active   6d4h
kube-node-lease   Active   6d4h
kube-public       Active   6d4h
kube-system       Active   6d4h
trade-system      Active   8s
```

선호하는 네임스페이스를 지속적으로 사용하기 위해 컨텍스트에 영구적으로 저장.  

```
$ kubectl config set-context my-context --namespace=trade-system
Context "my-context" created.

$ kubectl config get-contexts
CURRENT   NAME         CLUSTER    AUTHINFO   NAMESPACE
*         minikube     minikube   minikube
          my-context                         trade-system
```

> `kubectl config use-context` 를 사용하여 빠르게 클러스터 변경 가능    

삭제명령  

```
$ kubectl delete -f Namespace/namespace.yaml
namespace "trade-system" deleted
```


<!-- 
### ACR 리소스 그룹 생성 

Azure Container Registry(ACR) - 컨테이너 이미지 저장, 관리 레지스트리

```
$ ACR_NAME=sampleBeylessACR
$ ACR_RES_GROUP=$ACR_NAME
$ az group create --resource-group $ACR_RES_GROUP --location koreacentral
```

### ACR 레지스트리 생성  

```
$ az acr create --resource-group $ACR_RES_GROUP --name $ACR_NAME --sku Standard --location koreacentral
```

> sku : Stock Keeping Unit(다중 서비스 계층), ACR 생성을 위한 가격 정책  Standard 로 설정,

### 이미지 빌드

```
$ az acr build --registry $ACR_NAME --image photo-view:v1.0 v1.0
$ az acr build --registry $ACR_NAME --image photo-view:v2.0 v2.0
```

샘플 코드를 ACR에 업로드 후 빌드(docker build),  

### 생성된 이미지 확인  
```
$ az acr repository show-tags -n $ACR_NAME --repository photo-view
[
  "v1.0",
  "v2.0"
]
```

## `ACR` - `AKS` 연결

`Azure Kubernetes Service(AKS)` - 쿠버네티스 매니지드 서비스, 클러스터 생성, 운용 관리가능 

`AKS` 에 클러스터를 생성하고 `ACR` 에 생성한 컨테이너 이미지를 사용해 컨테이너 생성해보자.  


### Service Principle 생성


`AKS` 로 만든 클러스터가 `ACR`의 이미지에 접근하려면 권한을 부여할 필요가 있다.  
`AKS` 에 `Service Principle` 을 설정해보자.  

먼저 `Service Principle` 를 생성하기 위해 `az ad sp create-for-rbac` 명령을 수행하고 결과값인 비밀번호를 얻어야 한다.  

> RBAC: Rule base access control(역할 기반 액세스 제어)

ACR 을 기반으로 
```
$ ACR_ID=$(az acr show --name $ACR_NAME --query id --output tsv)
$ SP_NAME=beyless-acr-service-principle
$ SP_PASSWD=$(az ad sp create-for-rbac --name $SP_NAME --role Reader --scopes $ACR_ID --query password --output tsv)
$ APP_ID=$(az ad sp show --id http://$SP_NAME --query appId --output tsv)
```

```
$ echo $ACR_ID
/subscriptions/.../resourceGroups/sampleBeylessACR/providers/Microsoft.ContainerRegistry/registries/sampleBeylessACR
$ echo $APP_ID
4b2a7370-...-...-...-...66
$ echo $SP_PASSWD
bf0f4a65-...-...-...-...09
```

`Service Principle` 생성끝 

### AKS 클러스터 생성

먼저 클러스터가 포함될 리소스 그룹 생성  

```
$ AKS_CLUSTER_NAME=AKSBeylessCluster
$ AKS_RES_GROUP=$AKS_CLUSTER_NAME
$ az group create --resource-group $AKS_RES_GROUP --location japanwest
```

먼저 `koreacentral` 에서 사용 가능한 쿠버네티스 버전 확인  

```
$ az aks get-versions --location koreacentral --output table
KubernetesVersion    Upgrades
-------------------  ----------------------------------------
1.17.3(preview)      None available
1.16.7               1.17.3(preview)
1.15.10              1.16.7
1.15.7               1.15.10, 1.16.7
1.14.8               1.15.7, 1.15.10
1.14.7               1.14.8, 1.15.7, 1.15.10
```

안타갑게도 한국 내부에선 무료버전을 지원하는 `Standard_D1_v2` 버전의 AKS 를 생성할 수 없다.  
`location` 을 `japanwest` 로 설정해 생성 (2020-03-19)
```
$ az aks create \
 --resource-group $AKS_RES_GROUP \
 --name $AKS_CLUSTER_NAME \
 --location japanwest
 --node-count 1 \
 --kubernetes-version 1.13.11 \
 --node-vm-size Standard_D1_v2 \
 --generate-ssh-keys \
 --service-principal $APP_ID \
 --client-secret $SP_PASSWD

$ az aks get-credentials --admin --resource-group $AKS_RES_GROUP --name $AKS_CLUSTER_NAME
```

> 이상하게도 `unauthorized_client` 라는 에러와 함께 안될때 가 있는데 찾아보니 여러번 시도하면 된다고 한다...  
> 아마 azure 에서 `Service Principle` 생성 및 사용에 시간이 좀 걸리는 듯 하다.   
> 그래도 안된다면 아래 명령을 통해 `Service Principle` 을 삭제하고 위 과정을 다시 시작해보자.    
> `$ az ad sp list --display-name AKSBeylessCluster --query '[].objectId'`  
> `$ az ad sp delete --id ...`  


## kubectl

```
$ kubectl cluster-info
Kubernetes master is running at https://aksbeyless-aksbeylesscluste-10d7f6-d25fab61.hcp.japanwest.azmk8s.io:443
CoreDNS is running at https://aksbeyless-aksbeylesscluste-10d7f6-d25fab61.hcp.japanwest.azmk8s.io:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
kubernetes-dashboard is running at https://aksbeyless-aksbeylesscluste-10d7f6-d25fab61.hcp.japanwest.azmk8s.io:443/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy
Metrics-server is running at https://aksbeyless-aksbeylesscluste-10d7f6-d25fab61.hcp.japanwest.azmk8s.io:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy
```

```
$ kubectl get node -o=wide
NAME                                STATUS   ROLES   AGE   VERSION    INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
aks-nodepool1-14952662-vmss000000   Ready    agent   25d   v1.13.11   10.240.0.4    <none>        Ubuntu 16.04.6 LTS   4.15.0-1071-azure   docker://3.0.10+azure
```

```
$ kubectl get node -o=jsonpath='{.items[0].metadata.name}'
aks-nodepool1-14952662-vmss000000
```

 -->
