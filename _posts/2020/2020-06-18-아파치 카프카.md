---
title:  "아파치 카프카!"

read_time: false
share: false
author_profile: false
# # classes: wide

categories:
  - kafka

tags: kafka

toc: true
toc_sticky: true

---

# 개요 

> 출처: https://github.com/AndersonChoi/tacademy-kafka

## 용어 

- `Broker` : **카프카 애플리케이션 서버** 단위  
- `Topic` : **데이터 분리 단위**. 다수 파티션 보유  
- `Partition` : **레코드 저장소**. 컨슈머 요청시 레코드 전달  
- `Offset` : 각 레코드당 파티션에 할당된 **레코드 고유 번호**  
- `Consumer` : **레코드를 가져가는(polling) 애플리케이션**  
- `Consumer group` : **다수 컨슈머 묶음**  
- `Consumer offset` : 특정 **컨슈머가 가져간 레코드의 번호**  
- `Producer` : 레코드를 브로커로 전송하는 **레코드 저장 애플리케이션**  

파티션(메세지 저장소) 의 복제(고가용성) 을 위해 일반적으로 3개 이상의 `broker` 를 운영하며   
각 브로커마다   

기존의 `end to end` 방식의 연결 구조에서 `messaging broker` 방식으로 변경하기 위한 메세지 브로커 오픈소스  

![kafka1](/assets/2020/kafka2.png)  

기존의 위와같은 복잡한 파이프 라인 구조를 아래와 같이 `kafka` 를 통해 간편화 시킨다.  

![kafka1](/assets/2020/kafka1.png)  

확장(스케일 아웃), fall out 발생시 메세지 백업등의 안정성 제공은 덤이다.  

## 파티션 

다른 브로커와는 다르게 파티션이라는 저장공간을 제공하며 저장되는 리소스(메세지)의 백업, 복제 등을 제공한다.  

![kafka3](/assets/2020/kafka3.png)  


파티션을 나눔으로 여러개의 클라이언트(`consumer`) 가 각 파티션에 연결하여 동시에 처리할 수 있다.  

> 파티션 개수마다 `consumer` 를 사용해야한다. 물론 하나의 `consumer` 가 여러개의 파티션을 담당할 수 있다.   

파티션과 `consumer` 가 `N:1` 관계를 맺기에 `consumer` 끼리 경쟁할 필요가 없으며   
어떤 `consumer` 가 데이터를 어디까지 가져갔는지 파악가능하다.  

트래픽이 많아질수록 파티션과 `consumer` 를 늘리는 전략으로 스케일 아웃이 가능하다.  
단 파티션은 한번 늘리면 줄이는 것은 불가능함으로 파티션을 늘리기전 충분한 테스트 과정이 필요하다.  

반대로 파티션 개수보다 `consumer` 가 많아지면 추가생성된 `consumer`는 동작하지 않는다.  

## 컨슈머 그룹  

다른 메세지 브로커 역할을 수행하는 어플리케이션이 그렇듯  

여러개의 인스턴스가 동일한 `topic` 을 구독하고 있을때 중복처리를 방지하기 위한 그룹설정이 필요하다.  

![kafka5](/assets/2020/kafka5.png)  

그룹을 지정하고 `consumer` 생성후 파티션에서 레코드를 읽어가면 읽은 부분까지 `offset` 을 `kafka` 서버에 기록(`commit`)한다.  

그룹별로 `offset` 을 지정하기 때문에 같은 `topic` 에 대한 여러가지 로직을 수행하고 싶다면   
해당 레코드를 처리하는 여러 `consumer` 그룹을 생성하면 된다.  


## 복제  

![kafka6](/assets/2020/kafka6.png)  

여러개의 브로커를 구성하고 하나의 토픽에 여러개의 파티션을 지정하면 브로커별로 파티션을 나누어 저장한다.  

위의 그림의 경우 3개의 브로커에 3개의 파티션을 지정한 경우이다.  

모종이 이유로 브로커가 중단된다면 데이터 손실이 발생함으로 카프카에선 아래와 같이 복제정책을 사용한다.  

![kafka7](/assets/2020/kafka7.png)  

파티션이 많아질수록 동기화에 많은 리소스(네트워크, 저장소 등)가 사용됨으로 사용량에 따른 적절한 브로커 개수를 설정해야 한다.  



# 설치 

> `amazon linux 2` 기준 

`java jvm` 설치 필요

## kafka 실행 바이너리 다운  

`$ wget http://mirror.navercorp.com/apache/kafka/2.5.0/kafka_2.12-2.5.0.tgz`  
`tar xvf kafka_2.12-2.5.0.tgz`  

## 카프카 힙 용량 설정

`ec2` 에 맞게 `default 1GB` 아닌 `400m` 로 변경  

```
$ export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
```

`server.properties` 의 아래 설정 변경    
```conf
# 추적처리 해제 및 공인IP 로 수정 필요 
listeners=PLAINTEXT://:9092
advertised.listeners=PLAINTEXT://3.23.88.6:9092
```


## zookeeper 실행  


카프카는 일반적으로 단독 브로커(서버)로 실행되지 않고 여러개의 인스턴스로 브로커가 형성됨으로 `gateway` 역할을 하는 `zookeepr` 사용한다.  

![kafka4](/assets/2020/kafka4.png)  


> 향후 zookeeper 는 제외될 예정이라 한다.  

```
$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
# 실행 확인  
$ jps
4050 QuorumPeerMain
```

## kafka 실행  

설정한 `server.properties` 로 `kafka` 실행  


```
$ bin/kafka-server-start.sh -daemon config/server.properties
# kafka 실행 확인  
$ jps
4415 Kafka
```

## 로컬에 클라이언트 설치  

서버에 접속해 여러가지 기능을 수행할 수 있는 클라이언트 프로그램을 설치 및 압축해제

```
$ curl http://mirror.navercorp.com/apache/kafka/2.5.0/kafka_2.13-2.5.0.tgz --output kafka.tgz 
$ tar xvf kafka_2.13-2.5.0.tgz
```

# 운영  

## 토픽생성  

클라이언트 압축 해제후 `bin` 디렉토리 이동  

```
$ ./kafka-topics.sh --create --bootstrap-server 3.23.88.6:9092 --replication-factor 1 --partitions 3 --topic test
Created topic test.
```

파티션 3개로 `test` 라는 토픽 생성, `replication-factor` 는 현제 `kafka` 브로커가 하나뿐임으로 1개 밖에 설정 불가능하다.  

나중에 고가용성을 브로커 대수를 늘리고 래플리카 설정후 늘려보자.  


`test` 토픽에 지속적으로 메세지 전달, 파티션에 데이터가 계속 쌓이게 된다.  

```
./kafka-console-producer.sh --bootstrap-server 3.23.88.6:9092 --topic test
>hello
>kafka
>hello
```

`from-beginning` 는 파티션에 저장된 모든 데이터를 처음부터 가져옴  

```
./kafka-console-consumer.sh --bootstrap-server 3.23.88.6:9092 --topic test --from-beginning
kafka
hello
hello
```

받아오는 데이터를 보면 입력한 순서가 다른데 파티션 3개에서 데이터를 가져옴으로 가져오는 순서는 다르다.  

만약 파티션을 1개만 설정하게되면 큐 특성상 FIFO 로 데이터를 가져온다.  

파이프라인이 지속적으로 열려있음으로 계속 데이터를 삽입하고 메세지를 지속적으로 받아오는지 확인  


### 현재 접속중인 consumer 확인  

```
$ ./kafka-consumer-groups.sh --bootstrap-server 3.23.88.6:9092 --list
console-consumer-14607
```

현재 콘솔을 통해 하나의 컨슈머가 연결된 상태이다.  

## 그룹으로 가져오기  

```
$ ./kafka-console-consumer.sh --bootstrap-server 3.23.88.6:9092 --topic test -group testgroup --from-beginning
kafka
hello
hello
```

해당 토픽을 소비하는 그룹 `testgroup` 으로 만들고 데이터를 가져온다.  

그룹으로 가져올 경우 이미 앞에서 해당 그룹으로 데이터를 가져왔다면 다음부턴 그 이후의 데이터만 가져온다.  
다시한번 위의 명령을 실행시 아무 데이터도 가져오지 않는다. (첫번째 명령 실행시에 모두 가져왔음으로)

중복처리 방지에 매우 좋다!

또한 그룹을 달리해서 같은 데이터를 다른 로직으로 진행시킬 수 도 있다!


### 그룹 모니터링  

해당 consumer group 이 각 파티션당 어느 레코드까지 데이터를 읽어왔는지 확인 가능하다.  

```
$ ./kafka-consumer-groups.sh --bootstrap-server 3.23.88.6:9092  --group testgroup --describe
Consumer group 'testgroup' has no active members.

GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
testgroup       test            1          2               2               0               -               -               -
testgroup       test            0          1               1               0               -               -               -
testgroup       test            2          2               2               0               -               -               -
```

각 파티션마다 현재 `OFFSET`, 마지막 `OFFSET`, 일지못한 개수(`LAG`) 등을 알수있다.  

`LAG` 이 늘어날수록 해당 `consumer` 그룹이 데이터 처리를 하지 못한것임으로 관리가 필요하다.    

### 그룹 오프셋 초기화  

```
$ ./kafka-consumer-groups.sh --bootstrap-server 3.23.88.6:9092 --group testgroup --topic test --reset-offsets --to-earliest --execute
```

가장 낮은 오프셋으로 다시 초기화, `testgroup` 이 다시 해당 오프셋부터 가져오게 된다.  
해당 명령 수행후 모니터링 명령(`--describe`) 수행시 `LAG` 가 `LOG-END-OFFSET` 과 동일해진다.  

특정 파티션만 특정 `offset` 지정도 가능하다.  

```
$ ./kafka-consumer-groups.sh --bootstrap-server 3.23.88.6:9092 --group testgroup --topic test:1 --reset-offsets --to-offset 10 --execute
```

`test` 토픽의 1번 파티션의 `offset` 을 `10`으로 지정한다

# kafka producer

> 참고 코드: https://github.com/kouzie/tacademy-kafka

## 레코드 전달

레코드 전달시에는 토픽과 `value` 는 필수 옵션이며 

추가적으로 파티션, 키 등을 설정해서 전송할 수 있다.  

일반적으로 키는 레코드를 구분하기위한 구분자로 사용하며  
특정 파티션에 키를 설정해 해당 키만 가지는 레코드를 저장하기위한(순서 보장) 방법으로도 쓰이며  

중복처리를 위해 `key` 를 지정해서 여러개의 `consumer` 에서 한번만 처리되도록 설정도 가능하다.  

```java
// 토픽, value 지정 
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, data);
// 토픽, 키, value 지정  
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, Integer.toString(index), data);
// 토픽, 파티션, 키, value 지정  
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, PARTITION_NUMBER, Integer.toString(index), data);
```

아래 명령으로 키를 설정해서 보내면 하이폰과 함게 key, value 가 출력된다.  

```
$ ./kafka-console-consumer.sh --bootstrap-server 3.23.88.6:9092 --topic test --property print.key=true --property key.separator="-"
...
0-This is record 8
1-This is record 9
...
# 키를 설정하지 않을시 null 로 출력
null-This is record 0
```

## producer ack 옵션  

- `acks=0` - **가장 속도가 빠름, 유실 가능성 큼**  
메세지를 보낸 즉시 성공으로 간주, 리더 팔로우 파티션에 저장되었는지 확인 하지 않음
센서와 같은 일부 유실되더라도 흐름이 유지되는 경우 `acks=0` 을 사용  

- `acks=1` - **속도 보통 유실 가능성 있음, 기본값**  
적어도 리더 파티션에는 저장되었는지 확인, 확인후 성공처리, 
복제되기 전에 죽게된다면 유실될 가능성이 있다. 만약 브로커가 하나라면 유실가능성 없다.    

- `acks=all(-1)` - **속도 느림, 유실가능성 없음**  
리더, 팔로우 파티션에 모두 저장 성공되었는지 확인,  
모든 파티션에 저장되었는지 확인하기에 속도가 가장 느리다

이외에도 아래와 같은 옵션들이 있다.  

- `acks` : 레코드 전송 신뢰도 조절(리플리카)  
- `comression.type` : snappy, gzip, lz4 중 하나로 압축하여 전송  
- `retries` : 클러스터 장애에 대응하여 메시지 전송을 재시도하는 회수  
- `buffer.memory` : 브로커에 전송될 메시지의 버퍼로 사용 될 메모리 양  
- `batch.size` : 여러 데이터를 함께 보내기 위한 레코드 크기  
- `linger.ms` : 현재의 배치를 전송하기 전까지 기다리는 시간  
- `client.id` : 어떤 클라이언트인지 구분하는 식별자  


# kafka consumer 

데이터를 가져가는(`polling`) 하는 주체  

`commit` 을 통해 `consumer offset` 을 카프카에 기록 (어디까지 읽었는지)  

## 리벨런스

카프카의 특징은 파티션당 하나의 컨슈머가 담당하는것  

컨슈머 장애로(세션 끊김, 하트비트 불량) 인해 연결되어있던 파티션의 소유권이 변경때 일어나는 현상을 리벨런스라 한다.  

기본적으로 일정 시간마다 커밋을 진행하는데 이 시간이 다가오기 전에 장애로 리벨런싱 되면 데이터 중복 처리가 발생한다.  
때문에 애러 발생시에 만드시 진행했던 과정까지는 커밋을 수행해야할 필요가 있다.  


```java
static class RebalanceListener implements ConsumerRebalanceListener {
  @Override
  public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
    System.out.println("Lost partitions.");
  }

  @Override
  public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
    System.out.println("Assigned partitions.");
  }
}
```

# 모니터링에 텔레그래프 + kafka 사용하기  

텔레그래프가 시스템 모니터링을 위해 로그를 지속적으로 생성하고 `kafka` 에 적재할 수 있다.  

## 텔레그래프 설치  

시스템 모니터링을 위한 새로운 토픽 생성  

```
$ ./kafka-topics.sh --create --bootstrap-server 3.23.88.6:9092 --replication-factor 1 --partitions 5 --topic my-computer-metric
```

모니터링 툴로 `telegraf` 를 사용할 예정이다. 아래 방법으로 설치  

```
$ brew install telegraf
```

`telegraf` 가 지속적으로 모니터링 정보를 `kafka` 로 보낼수 있도록 `telegraf.conf` 생성  

```conf
[agent]
  interval = "10s"

[[outputs.kafka]]
  brokers = ["3.23.88.6:9092"]
  ## Kafka topic for producer messages
  topic = "my-computer-metric"

[[inputs.cpu]]
  percpu = true
  totalcpu = true
  fielddrop = ["time_*"]

[[inputs.mem]]
```

해당 `config` 파일위치로가서 `telelgraf` 실행  

```
$ telegraf -config telegraf.conf
```

카프카 클라이언트를 통해서 실제 시스템 로그가 파티션에 저장되고 있는지 확인  

```
$ ./kafka-console-consumer.sh --bootstrap-server 3.23.88.6:9092 --topic my-computer-metric --from-beginning
```