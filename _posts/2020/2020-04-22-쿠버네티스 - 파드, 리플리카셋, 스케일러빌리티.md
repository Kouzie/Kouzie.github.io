---
title:  "쿠버네티스 - 파드, 리플리카셋, 스케일러빌리티!"

read_time: false
share: false
author_profile: false
classes: wide

categories:
  - docker
  - kubernetes

tags: kubernetes

toc: true

---

# 파드 (Pod)

> Pod : 고래의 떼(pod of whales)  

파드는 쿠버네티스 애플리케이션의 기본 실행 단위, 쿠버네티스 객체 모델 중 만들고 배포할 수 있는 가장 작고 간단한 단위.  

특성은 아래와 같다.  

- 파드에는 하나 이상의 컨테이너가 들어있다.  
- 파드안의 컨테이너는 반드시 동일한 노드에 배치된다.  
- 어플리케이션 스케일 아웃은 파드단위로 이루어진다.  
- 파드안의 컨테이너는 네트워크와 스토리지를 공유한다.  

리플리카(`Replica`) - 동일한 구성으로 파드를 여러개 작성하여 배치하는 경우  

## 파드 - 네트워크  

각 파드에는 고유한 IP 주소가 할당되며 파드 내부의 컨테이너는 해당 IP 를 공유한다.  
때문에 파드내부의 컨테이너는 localhsot 를 통해 서로 통신가능하다.  

## 파드 - 스토리지  

파드는 컨테이너뿐 아니라 스토리지도 가지고 있으며 공유 볼륨을 통행 컨테이너끼리 스토리지를 통해 데이터를 주고받을 수 있다.  

![kube2]({{ "/assets/2020/kube2.png" | absolute_url }})  


# 파드 - 매니페스트 spec

파드의 내용을 설정  

|**필드**|**타입**|**설명**|
|---|---|---|
`containers` | `Container` 배열 | 파드에 속하는 컨테이너 목록  
`imagepPullSecrets` | `LocalObjectReference` 배열 | 컨테이너 이미지 취득을 위한 인증정보  
`initContainers` | `Container` 배열 | 초기화 처리를 하는 컨테이너  
`nodeName` | 문자열 | 해당 라벨의 노드에 파드를 배치(스케줄링)  
`nodeSelector` | `Object` | 해당 라벨의 노드에 파드를 배치(스케줄링)  
`priority` | 정수 | 파드의 우선순위 지정, 클수록 높음  
`restartPolicy` | 문자열 | 재시작 정책(`Always`, `OnFailure`, `Never`), 기본값은 `Always`  
`volumes` | `Volume` 배열 |  파드의 마운트할 볼륨 지정  

## Container

파드 매니페스트 속성의 `containers` 에 들어가는 객체 배열 `Container` 에 어떤 속성이 있는지 알아보자.  


|**필드**|**타입**|**설명**|
|---|---|---|
`args` | 문자배열 | 컨테이너에 송신할 인수  
`env` | `EnvVar` 배열 | 컨테이너에 설정한 환경변수  
`image` | 문자열 | 컨테이너 이미지와 해당 경로  
`imagePullPolicy` | 문자열 | 컨테이너 이미지 취득시 규칙(`Always`, `ifNotPresent`, `Never`). 기본값은 `ifNotPresent` 기존 이미지가 있으면 새로 취득하지 않는다. `Always` 설정시 항상 이미지 갱신  
`name` | 문자열 | 컨테이너 이름, 컨테이너 내부간에 통신할때 사용(`DNS_LABEL`)  
`ports` | `ContainerPort` 배열 | 컨테이너 공개파드  
`resources` | `ResourceRequirements` | 컨테이너에 CPU, Memory 같은 리소스 할당  
`volumeMounts` | `VolumeMount` 배열 | 컨테이너 마운트 볼륨 지정  
`workingDir` | 문자열 | 작업 디렉토리  
`livenessProbe` | `Probe` | 컨테이너 감시  
`readlinessProbe` | `Probe` | 컨테이너 감시  

# kubectl 파드 조작  

## 파드 생성 with private docker registry

`kubectl` 명령으로 파드를 조작하는 방법을 알아보자.  

먼저 간단한 이미지를 빌드하고 `private registry` 에 등록  

```
$ docker build -t photo-view:v2.0 .
$ docker image tag photo-view:v2.0 mydomain:5000/photo-view:v2.0

$ docker images
REPOSITORY                        TAG                 IMAGE ID            CREATED              SIZE
mydomain:5000/photo-view   v2.0                05e6c8ef4559        About a minute ago   924MB
photo-view                        v2.0                05e6c8ef4559        About a minute ago   924MB

$ docker image push mydomain:5000/photo-view:v2.0
```

> https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/

해당 `private registry` 를 `kubectl` 로 사용할 수 있도록 `secret` 쿠버네티스 리소스 생성  

`docker login` 을 통해 `$HOME/.docker/config.json` 파일에 인증데이터를 업데이트 후 해당 파일로 `secret` 리소스를 생성하자.  

```
$ kubectl create secret generic regcred \
--from-file=.dockerconfigjson=$HOME/.docker/config.json \
--type=kubernetes.io/dockerconfigjson
```

맥의 경우 key 정보가 config.json 에 저장되는 것이 아닌 별도의 키체인에 저장되어 있어 위의 명령을 사용해봤자 auth faild 오류가 발생할것이다.  
맥의 경우 바로 `kubectl` 에 `secret` 생성하는 아래의 명령 사용  

```
$ kubectl create secret docker-registry regcred \
--docker-server=mydomain:5000 \
--docker-username=admin \
--docker-password=admin
```

> `--namespace=''` 옵션을 생략했기에 기본적으로 default 에 적용된다.  

해당 이미지를 사용해 간단한 파드를 생성 

```yaml
# pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: photoview-pod
  labels:
    app: photo-view
    env: stage
spec:
  containers:
  - image: mydomain:5000/photo-view:v2.0
    name: photoview-container
    ports:
    - containerPort: 80
  imagePullSecrets:
    - name: regcred # 생성한 secret name 설정 
```

```
$ kubectl apply -f Pod/pod.yaml
pod/photoview-pod created

$ kubectl get pods --show-labels
NAME            READY   STATUS    RESTARTS   AGE     LABELS
photoview-pod   1/1     Running   0          2m13s   app=photo-view,env=stage

$ kubectl describe pods photoview-pod
// 상세정보 확인 가능
```

항상 `imagePullSecrets`를 매니페스트 파일에 적용해야만 다운이 가능한데 이를 `service account` 에 포함하여 생략할 수 있다.  

```
$ kubectl patch serviceaccount default -p '{"imagePullSecrets": [{"name": "regcred"}]}'
```

## 파드 변경  

새로운 이미지 `photo-view:v1.0` 을 빌드, 태그, `private-registry` 에 `push`

```
$ docker build -t photo-view:v1.0 .
$ docker image tag photo-view:v1.0 mydomain:5000/photo-view:v1.0
$ docker image push mydomain:5000/photo-view:v1.0
```

위에 생성한 `photoview-pod`의 이미지를 `photo-view:v1.0` 로 변경해보자.  

매니페스트 파일의 `image` 속성을 변경  

```yaml
# pod.yaml
apiVersion: v1
kind: Pod
...
spec:
  containers:
  - image: mydomain:5000/photo-view:v1.0
  ...
...
```

```
$ kubectl apply -f Pod/pod.yaml
pod/photoview-pod configured
```

`apply` 명령으로 생성/수정이 가능하다.  

파드 삭제  
```
$ kubectl delete -f Pod/pod.yaml
```


# 파드 스케줄링 구조  


스케줄링은 쿠버네티스 마스터 서버 `API Server` 에서 관리한다.  
파드가 마스터 서버에 의해 어떤 노드에 전개(스케줄링)될지 알아보자.  


`API Server`는 클러스터 안의 쿠버네티스 리소스를 관리(`CRUD`), etcd 에 접근지원 하기 위해 `Restfule` 인터페이스를 지원한다.  

파드가 생성되는 루틴은 대략적으로 아래와 같다.  

1. `kubectl` 명령 실행 - `API Server` 의 `RestAPI` 요청.  
2. 클러스터 구성 정보 갱신 - `kubectl` 로 인해 변경된 매니페스트 내용을 `etcd` 에 저장.  
3. 클러스터 구성 변경 - 젼달받은 매니페스트와 `etcd`의 데이터간 변화가 있다면 `API Server`에게 통지.  
4. 파드의 작성  - `API Server`가 통지받은 내용이 있다면 워커노드에 파드 업데이트 하도록 명령 송신, 노드내의 `kubelet` 은 전달받은 명령을 수행한다(새로운 파드 생성).  


3번과 4번 과정 사이에서 파드를 어떤 노드에 스케줄링할지 결정한다.  

스케줄링은 아래 2가지 규칙에 의해 결정된다. 

1. 노드의 필터링   
   - 파드에 NodeSelector 를 설정하고 있는지 검사  
   - 파드에 설정된 리소스 요구에 매칭되는 노드 필터링  
2. 노드의 우선순위  
   - CPU, Memory 사용량에 따라 노드의 우선순위 결정
   - 우선순위별로 파드를 배치  


## Minikube 에서 노드 생성  

파드와 반대로 노드는 쿠버네티스내에서 탑-레벨 리소스 이다.

현재 생성된 노드 확인  

```
$ kubectl get nodes
NAME       STATUS   ROLES    AGE   VERSION
minikube   Ready    master   8d    v1.18.0

$ kubectl describe node  minikube
Name:               minikube
Roles:              master
...
...
```

`minikube` 를 통해 새로운 가상의 노드 추가  

```
$ minikube node help
💡  Usage: minikube node [add|start|stop|delete]

$ minikube node add
😄  노드 m02 를 클러스터 minikube 에 추가합니다
👍  Starting node m02 in cluster minikube
🚜  Pulling base image ...
🤷  docker "minikube" container is missing, will recreate.
🔥  docker container (CPUs=2, Memory=1989MB, Disk=<no value>MB) 에 쿠버네티스를 설치하는 중 ...
🐳  쿠버네티스 v1.18.0 을 Docker 19.03.2 런타임으로 설치하는 중
🏄  m02 를 minikube 에 성공적으로 추가하였습니다!

$ minikube node add
😄  노드 m03 를 클러스터 minikube 에 추가합니다
👍  Starting node m03 in cluster minikube
🚜  Pulling base image ...
🔥  docker container (CPUs=2, Memory=1989MB, Disk=<no value>MB) 에 쿠버네티스를 설치하는 중 ...
🐳  쿠버네티스 v1.18.0 을 Docker 19.03.2 런타임으로 설치하는 중
🏄  m03 를 minikube 에 성공적으로 추가하였습니다!

$ docker ps
CONTAINER ID        IMAGE                                COMMAND                  CREATED             STATUS              PORTS                                                                           NAMES
c9e042c9462e        gcr.io/k8s-minikube/kicbase:v0.0.8   "/usr/local/bin/entr…"   4 minutes ago       Up 4 minutes        127.0.0.1:32785->22/tcp, 127.0.0.1:32784->2376/tcp, 127.0.0.1:32783->8443/tcp   minikube
01a38df1ed4a        gcr.io/k8s-minikube/kicbase:v0.0.8   "/usr/local/bin/entr…"   14 hours ago        Up 2 minutes        127.0.0.1:32791->22/tcp, 127.0.0.1:32790->2376/tcp, 127.0.0.1:32789->8443/tcp   minikube-m03
daaacf0b2652        gcr.io/k8s-minikube/kicbase:v0.0.8   "/usr/local/bin/entr…"   14 hours ago        Up 3 minutes        127.0.0.1:32788->22/tcp, 127.0.0.1:32787->2376/tcp, 127.0.0.1:32786->8443/tcp   minikube-m02

$ kubectl get nodes --show-labels
NAME           STATUS   ROLES    AGE     VERSION   LABELS
minikube       Ready    master   5m47s   v1.18.0   beta....
minikube-m02   Ready    <none>   4m35s   v1.18.0   beta....
minikube-m03   Ready    <none>   2m56s   v1.18.0   beta....
```

> 혹시 노드 설치간 문제가 생겼다면  
`$ minikube logs` 로 확인 후 에러 확인    
https://stackoverflow.com/questions/56966721/minikube-failed-to-start-node-minikube-not-found  
`$ minikube stop && minikube delete`

이미 수많은 `label` 이 설정되어 있지만 `minikube-m02` 노드에 `server=webap` 라벨을 추가한다.  

```
$ kubectl label node minikube-m02 server=webap
node/minikube-m02 labeled

$ kubectl get nodes --show-labels
NAME           STATUS   ROLES    AGE     VERSION   LABELS
minikube       Ready    master   5m47s   v1.18.0   beta....
minikube-m02   Ready    <none>   4m35s   v1.18.0   beta....,server=webap
minikube-m03   Ready    <none>   2m56s   v1.18.0   beta....
```

`minikube-m02`노드에 라벨이 적용된 것을 확인 후  
`nodeSelector`속성에 위에서 지정한 `label` 을 적용해 파드가 해당 노드에 만들어지도록 설정  

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: stage
spec:
  containers:
  - name: nginx
    image: nginx
  nodeSelector:
    server: webap
```

생성된 파드의 노드가 매니페스트에 설정한대로 `minikube-m02`에 적용되었는지 확인.  

```
$ kubectl create -f Pod/labels-node.yaml
pod/nginx created

$ kubectl get pod --output=wide
NAME    READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
nginx   1/1     Running   0          23s   172.18.0.2   minikube-m02   <none>           <none>
```

> `kubectl creat/apply` 차이: https://intellipaat.com/community/468/difference-between-kubectl-apply-and-kubectl-create  


## 파드 스케줄링 제어  

위의 `nodeSelector` 속성을 정의해 명시적으로 노드를 정해주지 않고도 스케줄링할 수있는 방법이 여럿 있다.  

### Affinity

> https://kubernetes.io/ko/docs/concepts/configuration/assign-pod-node/#어피니티-affinity-와-안티-어피니티-anti-affinity

`Affinity` 는 친밀감이란 뜻으로 서로다른 2개의 파드를 왠만하면 같은노드에 배치시키고 싶을때(`podAffinity`)  
혹은 다른노드에 배치시키고 싶을때(`podAntiAffinity`) 사용한다.  

또한 특정 조건을 갖춘 노드에서만 동작하도록 하는 `nodeAffinity` 도 있다.  


### Taints, Tolerations

> https://kubernetes.io/ko/docs/concepts/configuration/taint-and-toleration/

> Taints: 오염시키다
> Tolerations: 용인,관용

서로 상반되는 역할을 하는 명령  

`Taints`는 노드에 설정하는 것으로 파드를 스케줄링 하거나 조건에 맞는 파드만 스케줄링 하도록 할 수 있다.  
`Taints`가 설정된 노드에 파드를 배치하고 싶다면 `Tolerations` 설정이 필요하다.  


## 노드의 CPU, Memory 리소스 확인  

`kubectl describe` 명령으로 `node` 의 리소스 및 상세정보를 확인할 수 있다.  


```
$ kubectl describe node  minikube
Name:               minikube
Roles:              master
Labels:             beta.kubernetes.io/arch=amd64
                    ...
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    ...
CreationTimestamp:  Fri, 24 Apr 2020 09:51:25 +0900
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Fri, 24 Apr 2020 10:17:48 +0900
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Fri, 24 Apr 2020 10:16:44 +0900   Fri, 24 Apr 2020 09:51:21 +0900   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Fri, 24 Apr 2020 10:16:44 +0900   Fri, 24 Apr 2020 09:51:21 +0900   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Fri, 24 Apr 2020 10:16:44 +0900   Fri, 24 Apr 2020 09:51:21 +0900   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Fri, 24 Apr 2020 10:16:44 +0900   Fri, 24 Apr 2020 09:51:39 +0900   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  172.17.0.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  61255492Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             2037260Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  61255492Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             2037260Ki
  pods:               110
System Info:
  Machine ID:                 6b32bc7470d6492092cde0ca7a683eb8
  System UUID:                b1cea2e9-5445-49e4-a44c-46eaed5fafa9
  Boot ID:                    c1b830e3-1bda-41bc-8e9d-fc9cd9db4a76
  Kernel Version:             4.19.76-linuxkit
  OS Image:                   Ubuntu 19.10
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://19.3.2
  Kubelet Version:            v1.18.0
  Kube-Proxy Version:         v1.18.0
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (9 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  kube-system                 coredns-66bff467f8-5lkpn            100m (2%)     0 (0%)      70Mi (3%)        170Mi (8%)     26m
  kube-system                 coredns-66bff467f8-tmfwr            100m (2%)     0 (0%)      70Mi (3%)        170Mi (8%)     26m
  kube-system                 etcd-minikube                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         26m
  kube-system                 kindnet-pc7k4                       100m (2%)     100m (2%)   50Mi (2%)        50Mi (2%)      26m
  kube-system                 kube-apiserver-minikube             250m (6%)     0 (0%)      0 (0%)           0 (0%)         26m
  kube-system                 kube-controller-manager-minikube    200m (5%)     0 (0%)      0 (0%)           0 (0%)         26m
  kube-system                 kube-proxy-k2mfd                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         26m
  kube-system                 kube-scheduler-minikube             100m (2%)     0 (0%)      0 (0%)           0 (0%)         26m
  kube-system                 storage-provisioner                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         26m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (21%)  100m (2%)
  memory             190Mi (9%)  390Mi (19%)
  ephemeral-storage  0 (0%)      0 (0%)
  hugepages-1Gi      0 (0%)      0 (0%)
  hugepages-2Mi      0 (0%)      0 (0%)
Events:
  ...
```

`CPU`, `Memory` 리소스는 매니페스트 파일에서 설정 가능하다.  

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: requests-pod

spec:
  containers:
  - image: busybox
    command: ["dd", "if=/dev/zero", "of=/dev/null"]
    name: main
    resources:
      requests:
        cpu: 50m
        memory: 300Mi # (K M G T P), (Ki Mi Gi Ti Pi) 사용 가능
```

`Minikube` 에서 생성된 `node` 의 `CPU Limits` 는 `100m`, `Memory Limits`는 `390Mi`남아있다.
위의 매니페스트 설정대로 파드를 생성하고 줄어드는 `Limits` 를 확인  

`requests` 속성을 파드의 최소 리소스 요청 단위를 뜻한다.  

```
$ kubectl create -f Pod/pod-request.yaml
pod/requests-pod created 

$ kubectl get pods --output wide
NAME           READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
requests-pod   1/1     Running   0          39s   172.18.0.2   minikube-m03   <none>           <none>
```

`$ kubectl describe node minikube-m03` 명령으로 남은 리소스를 확인해보면 정확인 `CPU 50m`, `Memory 300Mi` 만큼 `Limits` 가 줄어있다.   

쿠버네티스에서 파드를 스케줄링할때 실제 노드의 리소스사용량이 아닌 메니페스트에 설정된 리소스 설정으로 스케줄링 됨을 알 수 있다.  
파드에 많은 리소스를 할당하게 되면 그만큼 다른 파드를 노드에 설정할 수 없다.

만약 파드에 설정한 `resources` 사용량을 넘게되면 쿠버네티스에서 어떻게 처리하는지 알아보자.  

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: limits-pod
spec:
  containers:
  - name: main
    image: polinux/stress
    resources:
      limits:
        cpu: 90m
        memory: 300Mi
    command: ["stress"]
    args: ["--vm", "1", "--vm-bytes", "500M", "--vm-hang", "1"]
```
`stress` 프로그램으로 `Memory`에 `300M`를 넘는 `500M` 를 설정하여 실행  

`limits` 속성은 파드 요청 제한 단위를 뜻한다.  

```
$ kubectl get pods --output wide
NAME         READY   STATUS              RESTARTS   AGE   IP       NODE           NOMINATED NODE   READINESS GATES
limits-pod   0/1     ContainerCreating   0          6s    <none>   minikube-m03   <none>           <none>

$ kubectl get pods --output wide
NAME         READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
limits-pod   1/1     Running   0          9s    172.18.0.2   minikube-m03   <none>           <none>

$ kubectl get pods --output wide
NAME         READY   STATUS      RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
limits-pod   0/1     OOMKilled   0          9s    172.18.0.2   minikube-m03   <none>           <none>

$ kubectl get pods --output wide
NAME         READY   STATUS             RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
limits-pod   0/1     CrashLoopBackOff   2          43s   172.18.0.2   minikube-m03   <none>           <none>
```

`$ kubectl describe pod limits-pod`로 상세 로그를 확인가능하다.  

쿠버네티스에선 복구기능을 갖고 있기에 오류가 감지되면 기본적으로 재시작한다.  
`restartPolicy`속성 에 따라 옵션이 다르며 기본값은 `Always` 이다.  

```
$ kubectl get pods --output wide
NAME         READY   STATUS             RESTARTS   AGE     IP           NODE           NOMINATED NODE   READINESS GATES
limits-pod   0/1     CrashLoopBackOff   6          7m15s   172.18.0.2   minikube-m03   <none>           <none>
```

시간이 지남에 따라 `RESTARTS` 횟수가 계속 늘어나고 있다.  

## 파드 감시  

파드가 제대로 동작하는지, 파드 내부의 서비스가 제대로 동작하는지 감시 하기 위해  
메니페스트에서 `livenessProbe` 속성을 추가한다.  

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-http

spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/liveness
    args:
    - /server
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: X-Custom-Header
          value: Awesome
      initialDelaySeconds: 10
      periodSeconds: 5
```

`livenessProbe` 를 통해 컨테이너에 `/healthz` URI 에 5초주기(`periodSeconds`)로 요청을 날리고 `200` ~ `400` 사이의 값이 반환될 경우 정상으로 간주한다.  
그 이외의 값이 반환될 경우 `kublet` 에 의해 컨테이너가 재시작 된다.  

서비스가 실행될 때 까지의 텀(`initialDelaySeconds`)을 10초로 설정한다.

`k8s.gcr.io/liveness` 이미지에는 10초동안만 `status code 200` 을 반환하고 그 이후로는 `status code 500`을 반환하도록 설정되어있다.  

10초 후 아래 명령어를 실행하면 
```
$ kubectl get pods --output wide
$ kubectl describe pod liveness-http
```

`CrashLoopBackOff` 상태값과 로그에 `Liveness probe failed: HTTP probe failed with statuscode: 500` 가 찍혀있는걸 확인 가능하다.  

> http 를 통한 파드 상태확인 외에도 tcp소켓, 명령 실행 등을 통해서도 상태확인이 가능하다. 
> https://kubernetes.io/ko/docs/concepts/workloads/pods/pod-lifecycle/#컨테이너-프로브-probe


# 리플리카셋

리플리카셋은 파드의 수를 유지하는 장치이다.  
파드가 자동으로 RESTART 하며 상태를 복구하는 것이라면

파드가 정지된 경우 리플리카셋이 자동으로 새로운 파드를 시작한다.  

## 리플리카셋 spec

매니페스트 기본 구성은 파드와 같다.  
`spec` 부분만 다른부분이 있는데 알아보자.  

|**필드**|**타입**|**설명**|
|---|---|---|
`replicas`|정수|클러스터 안에서 가동시킬 파드의 수(기본값 1)
`selector`|`LabelSelector`|어떤 파드를 가동할지 정의, 파드의 `template.metadata.label` 에 설정된 값과 일치해야함
`template`|`PodTemplateSpec`|실제 클러스터 내부 파드 수가 `replicas` 에 설정된 수보다 적을때 새로작성되는 파드**의 템플릿**
`template.metadata`|`Object`|템플릿의 이름, `Label`과 같은 메타데이터 
`template.spec`|`PodSpec`|파드의 상세정보를 설정  

즉 리플리카셋을 사용하려면 리플리카셋의 `spec` 과 파드의 `spec` 을 모두 정의해야한다.  

## kubectl 리플리카셋 조작  

```yaml
# ReplicaSet/replicaset.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: photoview-rs
spec:
  replicas: 5
  selector:
    matchLabels:
      app: photoview
  template:
    metadata:
      labels:
        app: photoview
        env: prod
    spec:
      containers:
      - image: mydomain:5000/photo-view:v1.0
        name: photoview-container
        ports:
          - containerPort: 80
```


```
$ kubectl create -f ReplicaSet/replicaset.yaml
$ kubectl get pods --show-labels
NAME                 READY   STATUS    RESTARTS   AGE     LABELS
photoview-rs-466w6   1/1     Running   0          3h35m   app=photoview,env=prod
photoview-rs-fwv2f   1/1     Running   0          3h35m   app=photoview,env=prod
photoview-rs-j46rr   1/1     Running   0          3h40m   app=photoview,env=prod
photoview-rs-n64z2   1/1     Running   0          3h35m   app=photoview,env=prod
photoview-rs-zk4bz   1/1     Running   0          3h35m   app=photoview,env=prod
```

수정과 삭제는 아래 명령 참고  
`yaml` 파일을 수정 후 `apply` 하면 기존 리플리카셋의 설정이 자동 수정/적용 된다.  

```
$ kubectl apply -f ReplicaSet/replicaset.yaml
$ kubectl delete -f ReplicaSet/replicaset.yaml
``` 

리플리카셋은 철저히 `metadata.labels.app` 을 통해서 관리된다.  

먼저 라벨명이 `photo-view` 인 **파드** 를 하나 생성  

```
$ kubectl apply -f ReplicaSet/pod-nginx.yaml
pod/nginx-pod created

$ kubectl get pod
NAME        READY   STATUS    RESTARTS   AGE
nginx-pod   1/1     Running   0          27s
```

그리고 리플리카셋으로 `photo-view` 라벨을 가진 파드 5개를 생성하도록한다.  

```
$ kubectl apply -f ReplicaSet/replicaset-nginx.yaml
replicaset.apps/nginx-replicaset created

$ kubectl get pod
NAME                     READY   STATUS              RESTARTS   AGE
nginx-pod                1/1     Running             0          79s
nginx-replicaset-cg8l7   0/1     ContainerCreating   0          2s
nginx-replicaset-hgkkd   0/1     ContainerCreating   0          2s
nginx-replicaset-kg5ks   0/1     ContainerCreating   0          2s
nginx-replicaset-p2w5f   0/1     ContainerCreating   0          2s
```

기존에 파드 매니페스트로 생성했던 `nginx-pod` 파드와 함께 4개의 추가 파드가 생성된다.  


# 스케일러빌리티

순간적으로 많은양의 요청이 들어올 경우 시스템 처리능력을 높이는 방법  

시스템 처리능력을 높이는 방법은 2가지가 있다.  

- 스케일 아웃(수평 스케일): 시스템 구성 서버 대수를 늘림으로 처리능력 향상, 로드밸런서를 추가해야 하며 시스템의 가용성이 높아진다.  
- 스케일 업(수직 스케일): 서버의 리소스(CPU, Memory) 를 증각 시켜 처리능령 향상  

수직이던 수평이던 파드와 노드단위로 스케일(처리능령 향상) 가능하다.  

처리량의 증가정도에 따라 파드를 스케일할지 노드를 스케일할지 결정한다.  

## 파드 수동 수평 스케일 (`kubectl scale`)  

`kubectl scale` 명령으로 파드 스케일을 늘릴 수 있다.  

리플리카셋으로 `nginx` 파드를 3개 생성  

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: photo-view
  template:
    metadata:
      labels:
        app: photo-view
    spec:
      containers:
      - image: nginx
        name: photoview-container
```


```
$ kubectl apply -f HPA/pod-scale.yaml
replicaset.apps/nginx-replicaset created

$ kubectl scale --replicas=8 rs/nginx-replicaset
replicaset.apps/nginx-replicaset scaled

$ kubectl get pod
NAME                     READY   STATUS    RESTARTS   AGE
nginx-replicaset-4bv5g   1/1     Running   0          19s
nginx-replicaset-4cjjq   1/1     Running   0          19s
nginx-replicaset-5z9qk   1/1     Running   0          19s
nginx-replicaset-bt98h   1/1     Running   0          19s
nginx-replicaset-c5fkk   1/1     Running   0          2m29s
nginx-replicaset-hnv8w   1/1     Running   0          2m29s
nginx-replicaset-nxtcn   1/1     Running   0          19s
nginx-replicaset-zbsd6   1/1     Running   0          2m29s
```
<!-- 
## 파드 자동 수평 스케일 (`HorizontalPodAutoscaler`)

`kubectl scale` 명령으로 수동으로 스케일하였다면 `HorizontalPodAutoscaler` 쿠버네티으 리소스를 사용해 자동으로 수평 스케일 가능하다.

쿠버는 `CPU` 사용률, 기타 메트릭을 체크해 파드 스케일이 가능하다.  


> 리플리카셋 외에도 각종 리소스에 스케일링 가능하다.  
- `RelicaSet`
- `Deployment`
- `Relication Controller`
- `StatefuleSet`

먼저 스케일전의 리플리카셋을 생성한다.  

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: busy-replicaset
spec:
  replicas: 2
  selector:
    matchLabels:
      app: busy
  template:
    metadata:
      labels:
        app: busy
    spec:
      containers:
      - image: busybox
        name: hpa-container
        command: ["dd", "if=/dev/zero", "of=/dev/null"]
        resources:
          requests:
            cpu: 100m
          limits:
            cpu: 100m
```

자동 스케일을 위해선 `requests`, `limits` 속성을 둘다 설정할 필요가 있다.  
내부에서 dd 명령을 통해 `limits` 인 `100m` 만큼의 코어가 되어있다.  

```
$ kubectl apply -f HPA/replicaset-hpa.yaml
replicaset.apps/busy-replicaset created

$ kubectl get pod --show-labels
NAME                    READY   STATUS    RESTARTS   AGE   LABELS
busy-replicaset-w97wr   1/1     Running   0          35s   app=busy
busy-replicaset-z5sh8   1/1     Running   0          35s   app=busy

$ kubectl top pod
Error from server (NotFound): the server could not find the requested resource (get services http:heapster:)
```

`get services http:heapster` 서비스를 사용 못하는데 `metrics-server` 에드온을 `enable` 해주면 된다.  

```
$ minikube addons list
|-----------------------------|----------|--------------|
|         ADDON NAME          | PROFILE  |    STATUS    |
|-----------------------------|----------|--------------|
| dashboard                   | minikube | disabled     |
| default-storageclass        | minikube | enabled ✅   |
| efk                         | minikube | disabled     |
| freshpod                    | minikube | disabled     |
| gvisor                      | minikube | disabled     |
| helm-tiller                 | minikube | disabled     |
| ingress                     | minikube | disabled     |
| ingress-dns                 | minikube | disabled     |
| istio                       | minikube | disabled     |
| istio-provisioner           | minikube | disabled     |
| logviewer                   | minikube | disabled     |
| metrics-server              | minikube | disabled     |
| nvidia-driver-installer     | minikube | disabled     |
| nvidia-gpu-device-plugin    | minikube | disabled     |
| registry                    | minikube | disabled     |
| registry-aliases            | minikube | disabled     |
| registry-creds              | minikube | disabled     |
| storage-provisioner         | minikube | enabled ✅   |
| storage-provisioner-gluster | minikube | disabled     |
|-----------------------------|----------|--------------|

$ minikube addons enable metrics-server
$ minikube addons open metrics-server
```
```
kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
busy-replicaset-8tgtp   1/1     Running   0          16s
busy-replicaset-nllr8   1/1     Running   0          16s
```

이 상태에서 자동 스케일 가능하도록 `HorizontalPodAutoscaler` 리소스를 작성  

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: budy-hpa
spec:
  minReplicas: 1   # 최소 리플리카 수
  maxReplicas: 5   # 최대 리플리카 수
  metrics:
  - resource:
      name: cpu
      targetAverageUtilization: 30  # CPU 가 30% 되도록 조정
    type: Resource
  scaleTargetRef:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: busy-replicaset
```

`HorizontalPodAutoscaler` 리소스 `spec`의 주의할점은  `minReplicas`, `maxReplicas`, `metrics`, `scaleTargetRef`

`metrics`: 스케일 하기위한 메프릭 설정  
`scaleTargetRef`: 자동스케일 대상 리소스(현재 리플리카셋)를 결정한다.  
kub
 -->