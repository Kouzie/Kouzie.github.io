---
title: "가상메모리"
read_time: false
share: false
toc: true
author_profile: false
classes: wide


categories:
  - OperatingSystem
tags:
  - KOCW
  - 반효경교수님
  - OS
---

## Virtual Memory (가상메모리)
물리메모리에 접근하는 주소변환은 OS가 관여하지 않는다 하였는데 가상메모리 기법은 전적으로 OS가 관리한다. 앞으로 가상메모리 기법을 살펴볼 때 우리는 paging기법을 통해서 알아볼 것이고 대부분의 OS도 이같이 동작중이다.  

***

### Demand Paging (페이지 요청 기법)
![os_11_1]({{ "/assets/OS/OS_11_1.png" | absolute_url }})   

demand paging은 요청이 있으면 해당 page를 메모리에 올리는 기법이다.  
프로세스가 자주 사용하는 주소공간은 전체 중에서 매우 일부이다. 자주 사용되지 않는 부분은 거의 대부분 방어코드이다. 특히 좋은 프로그램일수록 방어코드가 많고 이런 코드들은 예외가 발생하지 않는 이상 사용되지 않는다.  

demand paging은 이 같이 드물게 사용하는 코드들은 <u>요청이 들어오기 전에는 메모리에 상주시키기 않는 방법이다</u>. 이로써 얻는 장점은 다음과 같다.  
1. I/O양의 감소
2. 빠른 응답시간
3. Memory 사용량 감소
4. 더 많은 사용자 수용 
<br>

자주 사용하지 않는 메모리를 디스크로 내림으로써 시스템 전체적으로 I/O요청이 감소하고 성능이 향상된다.  

논리주소, page table, 물리주소는 전에 봤던 거고 Disk(backing store)가 추가됐다. A~F page는 실제 프로그램이 사용하는 page들이고 G,H는 사용하지 않는 page이다(공간 채우기용).  

demand paging기법에서 맨 처음 page table의 valid-invalid bit는 모두 invalid로 설정돼있을 것이고 해당 page가 사용되면서부터 valid로 설정되고 page table 해당 entry에 frame번호가 적용될 것이다.  

예를 들어 1번page(B)를 접근하려고 page table에 갔더니 invalid일 경우 page fault라는 trap을 MMU가 발생시키고 CPU제어를 자동적으로 OS로 넘긴다. 일종의 s/w interrupt라 보면 된다. 그럼 OS에 있는 처리루틴(page fault handler)를 invoke(발동)하고 처리과정은 다음과 같다.  
<br>

#### Page Fault 처리과정

1.Invalid Reference(잘못된 요청)인치 검사  
   
프로세스 주소가 잘못됐는지, 접근권한(읽기, 쓰기)이 맞는지 검사한다. Invalid Reference일 경우 강제 종료(abort process)시킨다.  
<br>
<br>

2.Get an empty page frame   

합당한 요청일 경우 빈 frame을 하나 얻어야하는데 물리메모리가 각종 프로세스들의 page들로 꽉 차 남는 frame이 없을 수 있다. 이런 경우 하나를 뺏어야한다(replace)  
<br>
<br>

3.해당 페이지를 disk에서 memory로 읽어오기.  

매우 느린 작업, disk I/O를 하게 되면 CPU는 page를 요청한 프로세스를 block상태로 변경(preempt)시키고 disk컨트롤에 I/O요청하고 다른 프로세스에게 넘어간다. disk I/O가 끝나면 CPU는 인터럽트가 걸리고 page table entry를 valid bit로 수정, frame번호를 기입하고 ready queue에 해당 process를 insert시킨다. 이 과정을 그림으로 표현하면 아래와 같다.  
![os_11_2]({{ "/assets/OS/OS_11_2.png" | absolute_url }})   

page fault(페이지가 물리메모리에 없을때)가 나면 당연히 I/O작업이 발생하게 되고 이는 메모리 접근 시간을 좌지우지한다.  
page fault비율이 0~1사이 일 때 실제 OS에서 비율을 조사해보면 거의 0.09~0.098 정도의 값이 나온다(거의 발생하지 않는다).  
<br>
<br>

![os_11_3]({{ "/assets/OS/OS_11_3.png" | absolute_url }})   
(1-p)는 page fault가 나지 않는 비율, 아래는 page fault가 나는 비율이다.  
곱하는 항목이 매우 많다, OS와 HW에서 page fault시 나는 오버헤드(문맥교환등) +  메모리 빈공간 없을시 swap되는 과정 등이 추가된다.

***

### Page Replacement
![os_11_4]({{ "/assets/OS/OS_11_4.png" | absolute_url }})   
<u>메모리에 자리가 없는 경우에 frame에서 page를 쫓아내는 과정</u>, 사용되는 알고리즘을 Replacement Algorithm, 가급적 page fault비율이 0에 가깝도록 하는 것이 목표이다.  

어떤 page가 희생양이 될 건지 구하고 disk로 swap out한다, 만약 victim page가 기존에 swap out되어 disk에 있었다 다시 memory에 올라온 경우일 때 swap in되고나서 변경된 내용이 있다면 다시 swap out할 때 disk에 I/O작업을 새로 해줘야 하고 변경된 내용이 없다면 memory에서 지우기만 하면 된다.  

page가 swap out되면 invalid bit로 변경하고 필요한 page를 disk에서 memory로 옮기다, 이 역할들은 모두 OS가 담당한다.  
페이지에 숫자를 붙이고 사용되는 순서 reference string이 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 일 때 한정된 메모리 안에서 어떻게 메모리가 올라가는지 어떤 알고리즘이 제일 좋은지 알아보자.  
<br>
<br>

#### Optimal Algorithm(최적 알고리즘)
![os_11_5]({{ "/assets/OS/OS_11_5.png" | absolute_url }})   
미래에 참조되는 페이지 순서를 다 안다고 가정했을 때 사용되는 알고리즘이다.  
그래서 실제 시스템에 적용해 볼 수 는 없다(미래를 알 수는 없으니까). Offline algorithm이라고도 한다.  

이 알고리즘은 가장 먼 미래에 사용되는 알고리즘을 가장 먼저 쫓아낸다. 빨강은 page fault가 난 경우를 뜻하고 연분홍은 page fault가 나지 않는 경우를 뜻한다. 5번 page가 들어오는 경우를 보면 1, 2, 3, 4 중에서 가장 먼 미래에 사용되는 4를 쫓아내고 5를 집어넣었다.  

미래를 알고있을 때 사용하는 알고리즘으로 이보다 더 좋은 알고리즘은 없다. 따라서 Optimal Algorithm은 모든 page교체 알고리즘의 기준을 제공한다(이러한 기준을 upper bound라 함 아무리 좋아도 이거보단 안 좋음).  
아래서 부터는 시스템에서 실제 사용되는 알고리즘을 소개하겠다. 시스템에선 미래를 예측하지 못하지만 미래와 비슷하게나마 동작하도록 예측해야 한다. 과거를 참조하면 된다.
<br>
<br>

#### FIFO(First In First Out) Algorithm
![os_11_6]({{ "/assets/OS/OS_11_6.png" | absolute_url }})   
먼저 들어온page를 먼저 내쫓는 알고리즘, 이상한 건 frame수를 늘려줬는데 page fault수가 증가했다는 것, 오히려 성능이 나빠졌다. 이러한 현상을 FIFO Anomaly(이상)라 한다. 
<br>
<br>

#### LRU(Least Recently Used) Algorithm
![os_11_7]({{ "/assets/OS/OS_11_7.png" | absolute_url }})   
현재 시스템에서 가장 많이 사용되는 알고리즘이다. 가장 오래전에 참조된, 덜 최근에 사용된 page를 내쫓는다. 최근에 참조된 것이 가까운 미래에 참조될 가능성이 높은 성질을 이용한 알고리즘이다.
<br>
<br>

#### LFU Algorithm(Least Frequently Used)
참조 횟수가 가장 적은 page를 내쫓는다. 과거에 참조된 적이 많은 page는 미래에 참조될 가능성이 높은 성질을 이용한 알고리즘이다.  
참조횟수가 동률일 경우 아무거나 내쫓고 조금이라도 성능을 높이고 싶다면 덜 최근에 사용한 page를 내쫓으면 된다.  

LRU와 LFU둘다 장단점이 있다, 그림을 통해 알아보자.
![os_11_8]({{ "/assets/OS/OS_11_8.png" | absolute_url }})   
오른쪽 그림은 page들의 참조시점을 시각적으로 표시한 그림. page5를 memory에 올릴 때 LRU는 가장 덜 최근에 사용된 page1을 내쫓고 LFU는 가장 사용률이 적은 Page4를 내쫓는다.
<br>
<br>

이 알고리즘들이 실제 어떤식으로 구현되는지 그림으로 알아보자.
##### LRU 구현 그림
![os_11_9]({{ "/assets/OS/OS_11_9.png" | absolute_url }})   
LRU는 최근에 참조된 시간 순으로 메모리에 올라와있는 page를 줄 세운다. Doubly linked list(양쪽에 모두 포인터)형식으로 구현돼있기 때문에 새로운 page가 추가되거나 순서가 바뀌는 것도 문제없다. 맨 위에 있는 page가 가장 오래전에 참조된page, 제일 아래가 가장 최근에 참조된 page이다.  

만약 어떤 page가 새로 메모리에 들어오거나 재참조 될 경우 가장 아래로 보내면 되고 쫓아낼 때는 가장 위에 있는 page를 쫓아내면 된다. List형태로 구현해 비교가 필요 없기 때문에 시간복잡도는 O(1)된다.  

LFU도 Linked list로 한 줄로 구현할 경우 효율이 가장 좋을까? 참조횟수를 page별로 일일이 비교를 해야 하기 때문에 좋지한다. 최악의 경우 모든 page와 모두 비교해야한다. 따라서 힙으로 구연한다.  
<br>
<br>

##### LFU 구현 그림
![os_11_10]({{ "/assets/OS/OS_11_10.png" | absolute_url }})   
힙(heap)은 최댓값 및 최솟값을 찾아내는 연산을 빠르게하기 위해 고안된 완전이진트리를 기본으로 한 자료구조이다.  

참조횟수가 가정 적은 page를 맨 위의 노드로, 아래 자식들은 자신보단 참조횟수가 적다. 참조횟수가 늘어 아래로 이동해야할 경우 자신 밑의 자식들과 비교하면 되기 때문에 트리의 높이만큼만 비교하면 된다. 쫓아낼 때는 최상위 노드를 쫓아내고 재구성 하면 된다. 복잡도는 O(log N)이다.

page교체 알고리즘에서 시간복잡도는 최소 O(1) ~O(log N)까지여야 한다.

***

### Clock Algorithm
사실 LRU와 LFU알고리즘은 실제 시스템에서 사용되지 않는다. 왜 그런지 그림과 같이 알아보자.  

![os_11_11]({{ "/assets/OS/OS_11_11.png" | absolute_url }})   
프로세스A가 CPU를 사용 중일 때 2번째 page를 참조하는 그림이다.

2번page는 이미 6번frame에 올라가 있기 때문에 주소변환만해서 접근하면 되서 Page fault가 나지 않는다. 이는 곧 I/O작업을 할 필요가 없기 때문에 OS개입도 없다는 뜻이다.  

OS개입이 없기 때문에 OS는 2번 page가 언제 몇 번 사용됐는지 체크할 수가 없다(LFU,LRU 사용할 정보부족). 

즉 page fault가 일어날 경우만 사용시간, 사용횟수를 체크해 줄 세울 수 있기 때문에 LRU, LFU알고리즘 실제 시스템에서 사용하는 것이 어렵다.
<br>
<br>

실제 시스템에서 page교체를 위해 사용되는 알고리즘은 <u>Clock Algorithm</u>이다.
![os_11_12]({{ "/assets/OS/OS_11_12.png" | absolute_url }})   
frame상에 있는 0 ~ 15번까지의 page를 둥글게 줄 세워놓은 그림이다(circular queue). 안의 숫자는 reference bit 다른말로 access bit이다(1bit크기, frame에 할당된 page마다 하나씩 있음).  

비트가 1일경우 최근에 사용된 페이지, 0일경우 최근에 사용되지 않은 페이지이다. clock알고리즘은 0과 1로만 최근에 사용했냐 안했냐를 표시한다. LRU처럼 최근에 사용된 순서대로 줄세울 수 없기 때문.

비트를 바꾸는 건 주소변환을 담당하는 하드웨어가 담당한다.  

frame에 사용할 page가 이미 있다면 reference bit를 1로 변경하고 page를 가져간다.  

만약 frame에 사용할 page가 없다면 page fault 인터럽트가 발생되고 **OS**가 그림처럼 frame을 돌면서 쫓아낼 page를 찾는다. 

쫓아낼 page를 찾는 과중중 OS는 다음일을 같이 수행한다, 가리킨 frame이 최근에 사용된 reference bit가 1이었다면 0으로 바꾸고 다음 frame이 page로 이동한다. 최근에 사용되지 않은 reference bit가 0인 frame을 만날 때 까지 반복한다. reference bit가 0인 frame을 만나면 해당 frame의 페이지를 쫓아낸다.  
<br>
<br>


#### Clock Algorithm의 개선
Reference bit 외에도 frame에 modified bit(dirty bit)라는 것이 추가된다.  

page에 최근에 읽기작업과 쓰기작업을 했는지 구분하기 위해 사용하는데 읽기가 발생했을 땐 reference bit를 1로, 쓰기가 발생했을 땐 reference bit와 modified bit를 둘다 1로 설정한다.  

따로 modified bit를 추가한 이유는 나중에 page가 사용되지 않아 쫓겨날 때 <u>그냥 쫓아내기만 하면 되는지, 아니면 쓰기작업이 발생해 backing store에 갱신까지 해서 쫓아내야 하는지</u> 구분하기 위해서다.  

따라서 modified bit는 메모리에 올라와 쓰기작업이 한번이라도 발생했다면 계속 1로 유지된다.

***

### page frame의 allocation
각프로그램마다 적어도 어느정도 page frame을 할당해 놓아야 원활하게 동작한다.  

예로 루프를 1000번 정도 도는 프로세스가 frame을 5개만 할당 받으면 page fault 없이 동작한다, 그런데 프로세스에 frame 5개를 할당하지 않고 3개만 준다면 루프 돌때마다 page fault가 여러 번 발생할 것이고 이는 비효율로 이어질 것이다.  

frame 2개 차이로 발생한 overhead치고는 대가가 너무 크다. 
<br>
<br>

#### page frame의 할당방법

1. equal allocation: 모든 프로세스한테 같은 크기만큼 frame 할당.
프로세스마다 크기가 다르기 때문에 공평하지만 효율적이진 않다.
 <br>
 <br>

2. proportional allocation: 프로세스 크기에 비례해서 frame 할당
<br>
<br>

3. priority allocation: 프로세스의 priority에 따라 다르게 할당
CPU를 바로 사용할 수 있는 프로세스에게 메모리를 많이 할당해주는 것이 효울적이기 때문에 CPU를 바로 사용할 확률이 높은, priority가 높은 프로세스에게 frame을 많이 주는방법.
<br>
<br>

위의 방법들은 모두 프로세스에 요구조건을 따라 어느정도 메모리를 할당시켜두는 방법이다.  

page frame allocation은 각 프로세스 마다 메모리를 어느정도 할당해 놓고 운영하는 방법, 그리고 아예 할당 개념 없이 모든 프로세스가 경쟁하면서 메모리를 사용하는 방법이 있다.
<br>
<br>

#### Global replacement:
프로세스 마다 메모리를 할당해 놓지 않고 운용하는 방법. 페이지를 쫓아 낼 때 어느 프로세스의 page인지 개의치 않고 알고리즘(FIFO, LRU, LFU등등)에 따라 쫓아내는 방식.  

모든 프로세스들이 경쟁해야 하기 때문에 자동적으로 정말 메모리를 많이 사용하는 프로세스에게 frame이 많이 할당되고, 메모리를 적게 사용하는 프로세스에겐 frame이 적게 할당된다.  

문제는 양극화가 점점 커지기 때문에 starvation이 발생할 수 있다.
<br>
<br>

#### Local replacement
프로세스마다 할당 해놓고 운용하는 방법. 프로세스A가 page fault가 발생하면 할당된 frame중에서 쫓아낼 page를 골라야 한다.  
FIFO, LRU, LFU등의 알고리즘을 process별로 운영한다.  

현대 시스템에선 위 두가지 개념을 적절히 잘 섞어서 사용한다.

***

### Thrashing
![os_11_13]({{ "/assets/OS/OS_11_13.png" | absolute_url }})   
Thrashing Diagram에서 X축은(degree of multiprogramming) 메모리에 올라가있는 프로세스 개수. Y축은 CPU 이용률이다.  

CPU 이용률이 100%가 되도록 사용하지 못하는 이유는 도중에 프로세스가 I/O작업을 하러가면 CPU가 놀게 되기 때문이다.  

프로세스가 메모리에 여러 개 올라가게 되면 I/O작업시에 발생되는 텀을 다른 프로세스가 사용할 수 있게 됨으로 CPU 이용률이 늘어나게 된다.  

즉 메모리의 모든 프로세스가 I/O작업을 하지 않는 이상 CPU는 계속 일한다.  

그런데 메모리에 올라간 프로세스 개수에 따라 CPU 이용률도 증가하다 어느정도 늘어나다 갑자기 CPU이용률이 뚝 떨어진다.  

뚝 떨어지는 현상을 Thrashing이라 한다.  
너무 많은 프로세스를 동시에 올려 놓아 모든 프로세스가 원활히 동작하기 위해 필요한 최소한의 메모리도 확보 못한 경우에 발생한다.  

모든 프로세스가 최소한의 메모리도 없으니 계속 page fault가 발생하면서 되려 CPU이용률이 떨어진다. Page fault 처리하느라 CPU가 계속 놀게 되는 현상이다.  

Thrashing을 막기위한 방법은 프로세스에게 필요한 최소한의 메모리를 보장하는 것이다(아까 말한 Local replacement).

***

### Locality of reference (page 참조의 집중성)
프로세스는 특정시간동안 특정 메모리공간만을 집중적으로 사용하는 특성을 뜻한다.  

예를 들어 특정 함수를 사용할 때 함수를 구성 page(code의 해당 함수부분)를 집중적으로 사용할 것이고 루프를 돌 때로 해당 루프를 구성하는 page를 집중적으로 사용할 것이다.  

이렇게 집중적으로 사용되는 page의 집합을 locality set이라 한다. 이런 locality set을 위한 메모리 할당은 보장해줘야 프로세스가 원활이 동작한다.
<br>
<br>

### Working-set Model
Locality set이랑 같은 뜻을 가진 용어다(Working set이 나중에 만들어짐).  
Working-set도 프로세스가 일정 시간동안 원활하게 수행되기 위해 메모리에 올라와 있어야 하는 집중적으로 사용되는 page들의 집합이다.  

Working-set을 관리하는 알고리즘들은 Working set에 포함되는 page 전부를 메모리에 상주시키려고 노력한다. 

만약 메모리 공간이 부족해서 해당 프로세스의 working set이 모두 올라가지 못할 경우 구차하게 working set의 일부분만 올리는 것이 아니라 해당 프로세스의 메모리를 모두 반납(swap out후 suspended)시킨다.
이전에 메모리에 올라가 있는 프로세스의 working set이라도 유시시키는 것이다.  

나중에 여유가 생겨 메모리에 모든 working set을 올릴 수 있을 때 swap out됐던 프로세스를 메모리에 올린다.

Working-set은 Global Replacement와 Local Replacement를 적절히 섞어 놓은 방법이다.  
각 프로세스별로 working set만큼의 메모리를 할당하되 프로세스끼리 경쟁하는 방법이다.  
<br>
<br>

#### Working-set Algorithm
![os_11_14]({{ "/assets/OS/OS_11_14.png" | absolute_url }})   
시간 순서에 따라 특정 프로세스의 page참조를 나열해 놓았다. 일단 working set을 알기 위해선 과거를 참조해서(과거에 많이 사용된 page) working set을 구성해야 한다.  

t1 시점의 델타만큼(window size)의 page참조 횟수를 분석해 만든 t1의 working set(WS)은 {1, 2, 5, 6, 7}이고 t2 시점의 WS는 {3,4} 이다.  

전에도 말했듯이 WS은 메모리에 전부 상주하거나 상주하지 못할시 프로세스 전체가 swap out된다.

ti 에 따른 WS 변화그림.
![os_11_14-1]({{ "/assets/OS/OS_11_14-1.png" | absolute_url }})   
<br>
<br>

#### Working-set bit
위에서 LFU나 LRU를 사용 못하는 이유가 물리메모리에 바로 접근해서 page접근 시 page참조 횟수를 OS가 기록 못하기 때문이라 했는데 위 그림의 working set에서 page reference table의 page 참조 횟수는 누가 구하는지 알아보자.  

WS을 구현 가능한 이유는 WS-bit가 프로세스 별로 존재하며 이는 하드웨어가 shift 연산을 통해 working set을 최신화 시켜준다.
![os_11_14-2]({{ "/assets/OS/OS_11_14-2.png" | absolute_url }})   
WS bit에 1이 하나라도 있으면 WS에 포함되어 있다는 뜻이고 window size(10)만큼 shift되어도 1이 남아 있다면 계속 WS에 존재, 1이 사라져 모두 0이 된다면 WS에서 퇴출당한다.  

Window size에 따라 WS허용 개수와 WS-bit 크기가 결정된다.  
(참고자료: http://www.cs.cornell.edu/courses/cs4410/2016su/slides/lecture13.pdf)

***

### PFF(page fault frequency) schema
![os_11_15]({{ "/assets/OS/OS_11_15.png" | absolute_url }})   

x축은 프로세스에 할당된 frame 개수, y축은 그에 따른 page fault 비율이다.  

WS이 자주사용되는 page를 할당시키는 방법이라면 PFF는 frame할당 비율을 적정 수준 유지시키는, 각 프로세스의 page fault 비율을 봐 가면서 메모리를 더 줄지 주지 않을지 결정하는 방법이다.  

그림처럼 어느정도 frame이 할당되면 page fault 감소비율이 점점 줄어든다(할당받은 frame값을 못함).  
frame할당을 늘리거나 줄여서 Upper bound와 lower bound 사이를 유지하는 것이 적절하다.  

이 방식 또한 적절한 구간에 들어가기 위한 메모리가 부족할 경우 프로세스 전체를 swap out시키고 메모리 여유가 생길 동안 대기시킨다.

***

###Page size의 결정
32bit OS에선 page size를 4KB를 쓴다 하였다. 하지만 요즘은 대부분 64bit OS를 쓰고 메모리크기도 많이 늘었다. 이에 따라 page 크기도 4kb보다 크게 바뀌는 추세이다(아직까지는 4KB를 가장 많이씀).  

Page 사이즈를 커지거나 작아지면 Page테이블크기, frame크기가 변한다.  
즉 메모리 효율이 증가하면(page크기가 작아지면) 시스템 성능이 떨어지고, 메모리 효율이 나빠지면(page크키가 커지면) 성능은 올라간다.

Locality set은 프로세스의 page reference는 특정 페이지를 집중반복 참조하는 특성도 있지만 참조한 page 주변 page를 참조할 가능성이 크다는 특징도 있다.  

주변 page크기가 작으면 page fault가 연쇄적으로 많이 일어나겠지만 만약 page 크기가 커지면 크기에 비례해서 page fault 발생이 적어진다.

