---
title: "메모리 관리 1"
read_time: false
share: false
toc: true
author_profile: false
classes: wide


categories:
  - OperatingSystem
tags:
  - KOCW
  - 반효경교수님
  - OS
---

### Logical Address와 Physical Address
![os_10_1]({{ "/assets/OS/OS_10_1.png" | absolute_url }})   
물리적인 메모리에는 아래에는 운영체제, 위에는 프로세스들이 올라가게 된다.  

물론 프로세스들은 바로 물리적 메모리를 통해 데이터 접근을 하지 않고 가상 메모리를 통해 데이터에 접근한다. 가상 메모리에서 물리 메모리로 접근할 때는 주소 변환 과정이 필요하다.  

우리가 프로그래밍 할 때 변수나 함수 이름을 사용해서 개발하지 변수와 함수의 주소를 사용해서 개발하진 않는다.  

이렇게 이름을 사용해 접근할 때 사용하는 것이 Symbolic Address다.  
컴파일이 돼서 실행파일이 만들어지게 되면 프로그램만의 독자적인 메모리 주소 <u>Logical Address</u>가 만들어 지고 정말 컴퓨터에서 실행되는 것은 <u>Physical Address</u>에서 실행된다.  

이 논리 주소가 물리 주소로 변환(Address Binding)하는 것은 하드웨어의 도움을 통해 이루어진다.

CPU가 바라보는 주소는 둘 중 어느 주소일까? CPU가 하드웨어라 물리메모리를 볼 것 같지만 논리주소를 바라본다.  

![os_10_2]({{ "/assets/OS/OS_10_2.png" | absolute_url }})   
그림을 보면 컴파일 돼서 만들어진 프로그램이 실행되고 물리주소에 프로세스의 코드가 올라간 걸 보면 논리 주소에서 사용하던 주소 값(A와 B의 주소, Jump주소)을 그대로 사용 중이다.  

즉 CPU가 논리주소에 맞닥뜨리면 Address Binding을 통해 물리주소에 접근해야한다.

***

### Address Binding

#### Compile time binding
<u>물리적 메모리주소(Physical Address)가 컴파일 시 정해지는 구조</u>로 옛날에 컴퓨터에서 프로그램 한 개만 실행되던 시절 사용하는 방법이다.  

범용 시스템에선 가장 아랫단에 OS가 올라가기 때문에 프로세스는 0번지부터 사용할 수 없다. 이렇게 컴파일러가 생성한 코드를 절대코드(Absolute code)라 한다.  
<br>
<br>

#### Load time binding
<u>프로그램이 실행될 때 Physical Address가 결정되는 구조</u>로 프로세스가 사용하는 물리적 시작 주소 위치는 랜덤하게 결정된다.  

이 구조에서 컴파일러가 생성한 코드를 재배치가능코드(Relocation code)라 한다.  
<br>
<br>

#### Rum time binding(Execution time binding)
<u>Load time binding과 마찬가지로 실행 시에 결정되는 구조</u>이다. 차이점은 Load time binding은 한번 실행되면 물리 주소 위치를 바꿀 수 없지만 Run time binding은 실행 도중에 위치를 옮길 수 있다.  

실행 중 물리주소가 언제 어디로 바뀔지 모르기 때문에 논리주소와 만날 때 마다 Address Mapping table을 사용해 Binding이 잘 돼있는지 점검해야한다.  

이 점검은 운영체제가 하지 않고 하드웨어 지원이 필요하다. CPU가 기계어를 실행 중에 논리주소 만나서 OS에게 점검해달라고 요청하고 다시 복귀하는 것은 비효율적이기 때문이다. 
 
***

### Memory Management Unit (MMU)

![os_10_3]({{ "/assets/OS/OS_10_3.png" | absolute_url }})   
위에서 말한 Logical Address를 Physical Address로 메모리 주소 변환을 지원하는 하드웨어이다.  

원래는 물리 메모리에 프로세스의 가상메모리가 그대로 올라가는 것이 아니고 쪼개져서 산발적으로 올라간다. 하지만 지금은 그림처럼 그대로 올라간다고 가정해보자(그대로 올라가는 방식을 <u>연속할당</u> 방식이라함).  

CPU가 346번지(논리주소)의 data를 요청, MMU는 해당 프로세스 데이터가 물리메모리 14000부터 올라가있기 때문에 그만큼 더해서 변환한다. 

물리메모리에 프로세스가 통째로 올라간다는 가정 하에 MMU에 레지스터 2개만 있으면 해결가능하다.  

접근할 프로세스 메모리 시작위치(최소값)를 갖고 있는 Relocation register(base register)와 메모리 범위를 결정하는 Limit register.  

굳이 Limit register를 두는 이유는 프로세스가 악의적으로 본인의 주소공간이 아닌 다른 프로세스의 주소공간을 요청할 수 있기 때문이다.
<br><br>

#### MMU 작동 그림
![os_10_4]({{ "/assets/OS/OS_10_4.png" | absolute_url }})   
요청한 주소가 limit register보다 작다면 정상적으로 진행시키고 아니라면 trap(소프트웨어 인터럽트)를 발생시킨다.  

정상적으로 진행된다면 Relocation register만큼 더해 memory에 접근하게된다.  

즉 CPU도 소프트웨어도 논리적인 주소만 보고 물리적 주소는 볼 수도 없고 알 필요도 없다.  
실행되어 메모리에 접근할 때 MMU에 의해서 물리메모리에 접근하게 된다.

***

### 프로세스가 메모리에 올라가는 여러 방식들

#### Dynamic Loading(동적 연결)
프로세스 전체를 메모리에 미리 다 올리지 않고 해당 루틴이 불릴 때마다 메모리에 Load하는 것. memory utilization(활용률)이 향상된다.  

좋은 프로그램들은 예외상황을 처리하는 오류처리 코드들이 많은데 이런 코드들은 평상시 사용되지 않는다. 이런 코드까지 메모리에 올리면 비효율적이기 때문에 Dynamic Loading을 사용해야 한다.  

Dynamic Loading은 옛날에 만들어진 용어로 원래 <u>OS지원 없이 프로그램 자체</u>에서 해당기능이 구현 됐을 때 생긴 용어다.  

현재는 OS가 이와 같은 기능을 라이브러리를 통해 지원한다(Dynamic loading 기술이라 봐도 무방함).  
<br>
<br>

#### Overlays(중첩)
메모리에 프로세스의 부분 중 실제 필요한 부분만 올리는 기술로 Dynamic Loading이랑 같은 개념이지만 더 옛날 기술이다.  

아주 작은 공간의 메모리를 사용하던 시절 프로그램이 메모리보다 클 때 상주부분과 그렇지 않은 오버레이 영역으로 구분하여 사용했던 기술이다. 수작업으로 프로그래머가 오버레이 구조를 설계해야 했다.
<br>
<br>

#### Swapping
![os_10_5]({{ "/assets/OS/OS_10_5.png" | absolute_url }})   
오리지널 개념은 프로세스 통째를 일시적으로 메모리에서 쫓아내는 것을 의미한다. 주로 Disk같은 보조기억장치로 쫓아낸다. 쫓겨난 메모리 공간을 Backing store(swap area)라 한다.
쫒겨날 때가 Swap out, 다시 메모리로 돌아올 때가 swap in.  

CPU 중기 스케줄러에 대해 배웠었다(프로세스1 참고). 너무 많은 프로세스들이 메모리에 올라가 있으면 비효율 적이기 때문에 메모리가 부족할 때 일부 프로세스를 골라 통째로 쫓아내는데 CPU 우선순위가 낮은(당장 CPU 사용 가능성이 적은)프로세스를 기준으로 먼저 처리한다.  

Compile time binding과 Load time binding은 프로그램이 종료될 때까지 같은 물리 주소가 유지돼야하기 때문에 Swapping에 제한이 있다(쫓겨나고 돌아올 때 그 공간에 다른 프로세스가 있을 수 있음).  
따라서 Swapping기능을 효율적으로 사용하려면 Rum time binding을 사용해야한다.  

![os_10_6]({{ "/assets/OS/OS_10_6.png" | absolute_url }})   
디스크에 접근(I/O요청)할 때 가장 많은 시간이 걸리는 부분은 디스크 헤드가 움직이는 시간이다(요즘은 SSD쓰니까 얼마 안 걸림). 헤드가 움직인 후 실제 데이터를 읽고 쓰는 시간은 굉장히 짧다.  

Swapping은 메모리에서 프로세스를 통째로 쫓아내고 불러오는 과정이기 때문에 File I/O랑 비교했을 때 훨씬 양이 많다.  

이례적으로 Swapping과정에서는 헤드가 움직이는 시간보다 데이터를 읽고 쓰는 시간이 더 많다(고화질 영화 옮기는 작업이랑 비교하면 안됨).  

현대 OS는 통째로 쫓아내는 경우도 물론 있지만 당장 사용하는 일부분만 올리고 일부분만 쫓아내는 Paging기법을 주로 사용한다(첫번째 그림참조).
<br>
<br>

### Linking
프로그램에 내가 만든 코드도 포함되겠지만 남이 만들어놓은 라이브러리들도 들어간다. 즉 자신의 코드와 라이브러리가 연결돼야 하는데 이 작업을 링킹이라 한다. 프로그램은 컴파일이 되고 각종 라이브러리들이랑 링킹이 되어 실행파일로 만들어진다.

#### Static Linking (Static Library)
라이브러리(내가 짠 코드가 아닌)가 내 만든 프로그램 실행파일 코드에 이미 포함돼있는 형태. 여러 라이브러리를 포함할수록 실행파일 크기가 커진다.  

따라서 동일한 라이브러리들이 각 프로세스마다 포함돼 있으면 메모리 낭비이다.
<br>
<br>

#### Dynamic Linking (Shared Library )
라이브러리가 내 실행파일에 포함되지 않고 별도의 라이브러리 파일(Shared Library)로 존재, 라이브러리 함수 호출시 파일을 찾아서 메모리에 올린 후 연결하여 실행, 찾기 위한 위치정보 코드(stub이라 함)만 실행파일 안에 포함돼있는 형태이다. 

라이브러리 파일을 공유하기 때문에 프로그램들이 라이브러리 함수가 필요할 때 마다 호출하여 같은 라이브러리 파일을 계속 메모리에 올리는 것이 아닌 한번만 하나만 올리고 사용하면 된다.  

Linux에서 Shared Library를 .so파일(Shared Object) 로 존재하고, 윈도우에선 .dll파일(dynamic-link library)로 존재한다.  

라이브러리가 이미 메모리에 있으면 그 라이브러리 파일의 호출한 루틴의 주소로 가고 없으면 디스크에서 읽어 올린다. 

***

### Allocation Of Physical Memory(물리 메모리 관리)

보통 낮은 주소영역에는 OS코드가 그 위에는 사용자 프로세스들이 사용한다. 이 사용자 프로세스 메모리 영역을 관리하는 <u>연속할당</u>과 <u>불연속할당 방법</u>을 알아보자. 연속할당은 별거 없지만 불연속 할당은 매우매우 알게 많다....
<br>
<br>

#### Hole
![os_10_7]({{ "/assets/OS/OS_10_7.png" | absolute_url }})   
연속, 불연속 할당을 알아보기 전에 Hole이란 용어를 알아야 한다.  

회색은 가용메모리 공간(비어있어 사용할 수 있는 공간)이고 Hole이라 한다. 연속할당 방법으로 프로그램을 실행하다보면 가용메모리 공간이 군데군데로 흩어지게 될 것이다.  

나중엔 가용메모리 용량은 충분하지만 흩어져 있어 정작 프로세스를 실행하지 못하는 상태가 생길 수 있다. 
<br>
<br>

#### Contiguous Allocation (연속할당)
프로그램이 쪼개지지 않고 통째로 메모리에 올라가는 방법, 주소변환이 간단하다. 연속할당은 두 가지로 나뉘는데 둘다 현대OS에는 사용되지 않는 방법들이다.

![os_10_8]({{ "/assets/OS/OS_10_8.png" | absolute_url }})   

#### 1. Fixed Partition (고정 분할 방식)
물리적 메모리를 여러 개 파티션으로 미리 나누어 놓은 형태. 프로그램 크기에 맞게 파티션 안에 할당하는 방식이다. 고정 분할 방식에선 내부조각과 외부조각들이 생긴다.  

프로그램B가 분할3보다 작기 때문에 분할3 내부 남는 공간이 내부 조각이 생긴다.  

프로그램B 입장에서 분할2역시 사용 못하는 남는 공간이기 때문에 외부 조각으로 본다.  

낭비되는 공간이 생기는 비효율적 방법이다. 남는 공간(조각)은 Hole로 봐도 무방하다.
<br>
<br>

#### 2. Variable Partition (가변 분할 방식)
메모리를 굳이 파티션으로 나누지 않고 사용하는 형태. 가변분할 또한 그림처럼 프로그램이 종료되면 남는 공간인 외부 조각이 생긴다. 내부를 칭할 파티션이 없어져서 내부조각은 생기지 않는다.  

가변분할 방식에서 크기n인 프로세스에 가장 적적한 hole을 찾는 방법이 3가지 있다. 당연히 프로세스 크기보다 Hole크기가 커야한다.  

1. First Fit: 크기가 n보다 큰 것 중 최초로 찾아지는 Hole에 할당. 장점은 빨리 결정하니 빠르다.  

2. Best Fit: 크기에 딱 맞거나 큰 것 중에선 제일 작은 Hole에 할당. 장점은 메모리 효율, 단점은 탐색해야하니 느리고 오히려 생겨나는 아주 작은 작은 조각들.  

3. Worst Fit: 제일 큰 Hole에 할당. 이름부터 단점. 쓰면 안 됨.  
<br>

이런 작은 조각들, 외부 단편화(External Fragmentation)를 해결하기 위해선 사용 중인 메모리 영역을 한군데로 몰고 Hole들을 다른 한곳으로 몰아 큰 block을 만들어야 한다. Compaction(압축)기법 이라한다.  

매우 비용이 많이 들고 프로그램들도 동적으로 메모리 주소가 바뀌어도 정상 실행 가능토록 해야 한다(Run time binding만 가능).
<br>
<br>

### Noncontiguous Allocation (불연속 할당)

프로그램을 구성하는 주소공간(Virtual Memory)이 여러 개로 잘려서 물리 메모리의 다른 위치에 올라간다.  

불연속할당은 연속할당의 물리메모리 관리처럼 레지스터 2개로만 관리 할 수 없다. 그렇다고 비싼 레지스터를 막 쓸 순 없으니 page란 걸 사용하여 관리한다.  
<br>

#### Paging
프로세스의 메모리 공간을 동일한 사이즈의 page로 나눈다. 32bit OS기준 보통 4KB로 나뉜다.  

물리메모리에 page를 올리기 위해 물리메모리를 page와 동일한 크기로 나누고 이를 frame이라 한다(page크기=frame크기).  

당장 필요한 page는 물리메모리에, 그렇지 않은 page는 backing storage에 저장해 놓는다. 참고로 불연속 할당에선 외부조각이 발생하지 않고 내부조각만 발생한다(모든 프로세스가 4kb로 딱 떨어지지 않고 생기는 자투리 때문에).  

32bit OS는 2의 32승인 4GB만큼 메모리를 인식한다. 즉 프로그램이 최대로 사용할 수 있는 메모리 또한 4GB이다. 이를 페이지단위인 4KB로 자르면 100만개정도 된다. 레지스터를 100만개 쓸 순 없으니 page들은 관리할 page table을 사용해야한다.
<br>
<br>

#### Page Table

![os_10_9]({{ "/assets/OS/OS_10_9.png" | absolute_url }})   
page table을 사용해서 프로세스 virtual memory에서 물리메모리에 접근하는 그림이다.  

연속할당에선 논리주소와 물리주소간의 주소변환을 레지스터로 했다면 여기선 page table을 사용하여 변환한다. page는 배열 형태로 entry(배열의 index)를 가지고 있고 크기는 4byte이다.  
page table 상자밖의 숫자가 entry, 상자안의 숫자가 frame number.  

위 그림에는 프로세스의 모든 page가 물리메모리에 올라가있지만 그렇지 않을 수도 있다, 보조장치에 올라가있거나 아예 해당 페이지를 사용하지 않을 수 도 있다.  

![os_10_10]({{ "/assets/OS/OS_10_10.png" | absolute_url }})   
모든 page가 메모리에 올라가 있지 않은 그림이다. 올라가지 못한 page는 table 안의 frame number는 0이 되고 그림처럼 entry마다 Valid-Invalid bit로 별도 표시한다.  

그림엔 없지만 protection bit라고 write, read, read only 접근권한을 표시하는 bit도 entry마다 있다.  
<br>
<br>

#### page table을 사용한 Address Binding
![os_10_11]({{ "/assets/OS/OS_10_11.png" | absolute_url }})   

그림의 p는 page번호(entry), f는 frame번호, d는 offset으로 해당 frame의 상대적 주소위치를 표시한다.  

page에서 d만큼 아래위치한 데이터에 접근하고 싶을 때 f에서 d만큼 아래위치한 데이터에 접근하면 된다.  

cpu에서 실제 연산할때 p와 d는 relocation register과 limit register에 저장하고 page table은 물리메모리에 저장하면 된다.  
그리고 CPU가 page table을 접근, 관리하기 위한 레지스터 2개가 있다,
table위치를 가리키는 page table base register(PTBR), table크기를 보관하는 page table length register(PLTR)가 있다.  

각 프로세스별 page table의 entry는 100만개정도 되는데. 이 table들은 main memory(물리메모리)에 상주한다. 

page table이 메모리에 있기 때문에 프로세스 virtual memory에 있는 데이터를 실제로 접근하려면 물리메모리에 총 2번 접근해야 한다. page table접근할 때 1번, 주소변환 거치고 데이터 접근할 때 1번. 물리 메모리 접근은 속도 저하로 이어진다(레지스터가 메모리위치 주면 MMU거쳐서 이러쿵 저러쿵 그리고 레지스터와 메모리와의 속도차이는 비교 불가).  
<br>
<br>

#### Translation look aside buffer(TLB)
![os_10_12]({{ "/assets/OS/OS_10_12.png" | absolute_url }})   

address binding속도향상을 위해 주소변환 전담 캐시메모리 translation look aside buffer(TLB)를 사용한다.  
캐시메모리는 메모리와 CPU사이에 속도 차이를 완충하기 위한 저장장치라 보면 된다. 

먼저 TLB에 page와 매칭 되는 frame number가 있는지 확인하고 없다면(TBL miss)어쩔 수 없이 page table을 사용한다.  

그림에는 page table이 물리메모리 밖에 있는 것처럼 보이지만 안에 있다. 2번 접근하면 속도 저하 때문에 물리메모리 접근이 필요 없는 TLB를 사용한다.  

90page에 해당하는 물리메모리의 frame에 접근하고 싶다면 page table은은 배열 형태로 돼있기 때문에 index(entry)를 사용해서 90*4KB위치로 가서 바로 frame number를 읽으면 된다.  

하지만 TLB는 index가 순차적으로 있는 게 아니다(자료구조도 다름), 쓰지 않는 page는 중간 중간 빠져있을 수 있다. 따라서 전부 search를 해야 하는데 이러면 오버헤드가 크기 때문에 associative register라는 병렬 search가 되는 하드웨어를 사용해야한다(그림 보면 TLB옆 화살표가 여러개).  

추가로 OS에서 프로세스가 여러개 실행된다면 page table도 여러 개이다. 하지만 TLB는 1개뿐이다. 따라서 CPU가 문맥교환으로 인해 실행하는 프로세스가 바뀐다면 TLB안의 값을 전부 flush(소멸)하고 다시 채워 넣어야 한다. 문맥교환으로 생기는 오버헤드 몇개인지...
<br>

TLB를 통한 메모리 접근 시간이 어떻게 되는지 알아보자.
![os_10_13]({{ "/assets/OS/OS_10_13.png" | absolute_url }})   
1. TLB 접근시간 = ε.
2. 메모리 접근시간 = 1.
3. Hit radtio - TLB에 의해 주소변환이 이루어지는 비율 = α
4. TLB miss는 1-a
참고로 TLB에 의해 메모리 접근하는 비율 Hit ratio는 거의 1에 가깝다. 자주쓰는 페이지는 정해져 있고 우리는 TLB로 접근만 하면됨.
결론, 메모리 접근 시간이 매우 매우 단축됨.
<br>
<br>

#### Two Level Page table (2단계 page table)
page table의 장점은 프로그램을 동일크기의 page로 잘라 필요한 page만 메모리 아무 곳에 올려도 되기 때문에 메모리 관리가 효율적이다.  

단점은 page table의 한 배열(entry) 안에 4BYTE정도의 메모리 위치정보가 들어있는데 이 entry 수가 100만개가 넘는다(32bit기준).  

즉 프로세스 당 4MB(4BYTE*100만)정도의 공간이 필요한데 4GB메모리 입장에선 4MB메모리 할당이 부담된다. 그래서 사용되는 것이 2단계 page table이다. 2단계뿐 아니라 다단계 page table을 사용할 수 도 있다.

![os_10_14]({{ "/assets/OS/OS_10_14.png" | absolute_url }})   
그림을 보면 바깥 page table, 안쪽 page table을 거쳐 메모리에 접근하는 것을 알 수 있다. page table이 하나였을 때도 메모리를 2번 접근하는 손해가 있었는데 2단계가 되면서 3번 접근하게 됐다. 속도는 손해지만 공간은 이득이다.  

그림만 보면 속도도 공간도 2배 손해인 것처럼 보이지만 아니다. 어떻게 메모리 공간을 아끼는지 알아보자.  

프로세스가 사용할 수 있는 주소공간이 4GB라고 메모리에 4GB만큼 차지하지 않는다. 이유는 프로세스는 stack, code, data로 구성되고 이를 100만개 page로 나누어 메모리에 필요한 부분만 올린다. 여기서 필요 없는 공간은 code와 stack사이에 비어있는 공간이다. 이 공간이 매우 큰데 이 부분은 물리메모리에 올라갈 일이 없다..  
즉 100만개 page중 일부만 메모리에 올리고 나머지는 Backing store저장된다.  

쓰지도 않는 부분을 위해 page table의 entry를 사용하면 낭비가 심하다.  

page table도 100만개 entry를 다올리지 말고 필요한 entry들만 올리면 되지 않을까? 즉 page table을 page화 시켜 공간을 절약하는 것이다.   

바깥쪽 page table안에 사용되지 않는 page의 정보는 null로 설정되어 있고 <u>안쪽 page table이 생성되지 않는다<u>(여기서 절약).  

생성된 안쪽 page table은 page화 되어 물리메모리 frame안에 들어 가야하기 때문에 4MB였던 크기는 4KB로 쪼개진다.  
쪼개진 4KB를 4BYTE로 나누면 생성되는 entry수는 1024(1K)개다. 4BYTE는 32bit 주소를 표현하기 위한 가장 작은 값이다.  

즉 쪼개진 안쪽 page table하나가 1024개의 frame, 4KB(frame크기)*1024=4MB 물리메모리를 커버할 수 있다.  

프로세스가 물리메모리에 올라가는 크기만큼만 안쪽 page table을 쪼개서 올리면 된다.

예를 들어 실제로 물리메모리에 올라가 사용하는 크기가 26MB인 프로세스가 메모리에 올라갈 때 바깥 page table 4KB, 안쪽 page table 4KB*7(28MB커버), 총 32KB만 있어도 페이징이 가능하다, 바깥 page talbe 크기가 4KB인 이유는 쪼개진 안쪽 page table 7개를 가리키기 위해서(더 작아도 되지만 frame최소 단위가 4KB이기 때문).  
4MB와 비교해서 장족의 발전.  
<br>
<br>

#### Two Level Page table 의 address bindging

![os_10_15]({{ "/assets/OS/OS_10_15.png" | absolute_url }})   
2단계에선 주소변환 과정이 3부분으로 나누어진다. d는 4KB를 BYTE단위로 표시위한 2의 12승인 12bit(4KB중 어딘가 접근해야하기 때문에), p1, p2는 각각 바깥쪽 안쪽 페이지 테이블의 순번(entry)이고 크기는 4KB를 4BYTE로 나눈 1K개를 표시위한 2의 10승인 10bit이다.

![os_10_16]({{ "/assets/OS/OS_10_16.png" | absolute_url }})   
높은 숫자의 다단계로 갈수록 메모리절약이 가능하다. 대신 메모리를 다번 접근해야 하지만 TLB로 커버가능하다.  

아까 말했듯이 극히 일부의 page만 메모리에 올려 사용하기 때문에 TLB의 Hit ratio는 매우 높다.
<br>
<br>

지금까지 논리주소에서 물리주소로 변환되는 과정을 배웠는데 여기서 OS가 하는 역할은 하나도 없다. 모두 하드웨어가 역할이고 지원해준다(MMU).

***

지금까지 불연속 할당의 paging방법을 보았는데 page를 사용한 다른 방법들을 보자.  

### Inverted page table (역방향 페이지 테이블)
![os_10_17]({{ "/assets/OS/OS_10_17.png" | absolute_url }})   

역시 메모리 공간 낭비를 막기 위한 방법 중 하나이다. 물리적 메모리 frame과 entry의 위치가 동기화 되어있다, 그래서 page table도 프로세스별이 아닌 frame과 동기화된 <u>프로세스들이 같이 쓰는 page table 하나만 있으면 된다</u>. 물리 메모리를 그대로 page table로 본뜨는 것.

process P1 논리주소의 p번째 page를 물리메모리에서 찾기 위해 page table에서 수색하고 찾은 f번째 entry에서 찾았다면 같은 위치인 f번째 frame으로 가면된다.  
page table을 순차적으로 다 뒤져야 되기 때문에 오버헤드가 크다. 논리주소에서 물리주소로 변환하는 과정에선 효율이 나쁘다, 대신 물리주소를 사용해 논리주소를 찾아가는 것이 더 간편한 구조로 이루어져있다.  

위에선 말한 associative register같이 병렬처리가 가능한 하드웨어로 page table을 구성한다면 시간도 아끼고 공간도 아낄 수 있겠지만 비싸다. 
<br>
<br>

### shared page
![os_10_18]({{ "/assets/OS/OS_10_18.png" | absolute_url }})   
그림을 보면 프로세스가 page 크기로 잘려있고 각각 page table을 갖고 있으며 물리메모리 frame에 일부가 올라가 있다. 그런데 각 프로세스의 1~3 page를 보면 모두 3,4,6번 frame에 올라가있다.  
이렇게 된 이유는 이 3개 다 동일한 프로그램이기 때문이다. 프로그램이 같으면 code는 똑같고 data만 다르다.  
동일한 code를 여러 개 올리면 낭비니까 공유해서 쓰자는 개념이 shared code이다(Re entry code또는 pure code라고도 한다).  

전에 Inter-Process Communication(IPC: 프로세스 간 통신)개념에서 shared memory와는 다른 개념이다. shared memory는 통신개념으로 프로세스간 읽고 쓰기가 가능했지만 shared code는 읽기만 가능하다. 그리고 shared code는 프로세스들의 논리 주소도 일치해야 한다(물리주소야 당연히 같다).   
이유는 컴파일된 프로그램 코드에서 CPU가 주소이동을 할 때 논리주소를 쓰지 물리주소를 쓰지 않기 때문이다. 상대적 주소 관점으로 프로세스의 code 논리주소가 이동하면 코드안의 내용(함수, 변수위치)도 바꿔야하는데 이미 컴파일된 코드가 바뀔 순 없다.  

그리고 프로세스의 data나 code도 개별적으로 필요할 수 있는 부분을 private code & data 라고 한다. 
<br>
<br>

### Segmentation
paging기법에선 동일 크기로 프로세스 논리주소를 잘랐다면 <u>segmentation은 의미를 기준으로 자르고 이를 segment라 한다</u>. 일반적으로 크게 code, data, stack 영역을 잘라 3개의 segment로 만들 수 있고, 또는 작게 code 영역을 main(), function, 전역변수, 배열, symbol table 등으로 작은 단위(logical unit)로 자를 수 있다.  
segmentation도 paging기법처럼 segment table이 있고 앞에는 segment번호, 뒤에는 offset으로 구성된다.  

![os_10_19]({{ "/assets/OS/OS_10_19.png" | absolute_url }})   
s는 segment번호, d는 offset이다. s번째 segment를 segment table에서 찾아서 물리메모리 시작위치인 base를 찾아 d만큼 떨어진 위치로 접근한다. segment길이가 다르기 때문에 paging의 frame번호와는 다르게 base에는 BYTE단위 주소가 들어간다.  
paging기법과는 다르게 시작위치 말고 limit도 있는데 segment의 크기가 제각각이기 때문에 잘못된(불순한) 위치접근을 막기 위해 별도로 크기정보를 가지고 있다.  

segmentation기법도 레지스터가 필요하다. paging기법에선 limit register, relocation register를 PTBR과 PTLR로 썼는데 segmentation또한 segment table위치와 segment의 수(segment table의 길이)를 저장하는 STBR register, STLR register를 사용한다. 만약 segment번호 s가 STLR register에 저장된 값보다 크다면 잘못된(불순한) 접근이다.
<br>

논리주소가 segment로 나눠져 물리주소로 어떻게 들어가는 그림을 통해 알아보자.
![os_10_20]({{ "/assets/OS/OS_10_20.png" | absolute_url }})   

limit는 segment의 길이, base는 시작위치 정도로 보면 되겠다. paging처럼 잘게 잘리는 것이 아니기 때문에 segment가 어떤 이유로 빠져나가게 되면 크기가 다른 hole(외부조각)이 발생하기 때문에 segmentation기법에선 segment를 어느 조각에 넣어야 하는 문제가 생긴다(연속할당 참조).  

segmentation기법의 장점은 의미단위로 나누기 때문에 의미 단위로 하는 일들은 쉽게 처리가능하다. 공유와 보안 같은 것들을 예로 들 수 있다. code segment를 공유시키고 ode와 stack은 함부로 변경 못하도록 보안하고(read, write권한지정), 의미단위로 쪼개진 segment를 통째로 처리하면 되니까 수월하다. 단점은 역시 가변크기다 보니까 hole이 생기는 것이다.

물론 권한지정은 paging기법에서도 read, write권한을 페이지별로 줄 수 있지만 크기단위로 자르다 보니 4KB페이지 안에 일부는 code, 일부는 data가 섞여있을 수 있다. 
<br>
<br>

### Shared segment
![os_10_21]({{ "/assets/OS/OS_10_21.png" | absolute_url }})   
shared page와 유사하다. segment를 공유하려면 논리주소에서 나눠진 segment번호는 같아야한다.
segment table 크기도 작고 메모리도 더 아낄 수 있고 table이 작기 때문에 통째로 cache에 올리면 속도도 빠르겠지만 실제 segmentation기법은 현대OS에서 거의 사용되지 않는다. 대부분 paging기법을 사용한다. 사용한다 해도 paging과 혼합해서 사용한다.
<br>
<br>

### Segmentation With Paging (segment와 page혼합)
![os_10_22]({{ "/assets/OS/OS_10_22.png" | absolute_url }})   

이 방법은 segment가 통째로 올라가지 않고 page화 되어 메모리에 올라간다. 결국은 page단위로 잘려 올라가기 때문에 메모리도 frame단위로 잘려 관리된다.  

논리주소에서 segment번호s와 STBR을 통해 segment table의 해당 entry로 이동, entry에서 segment마다 존재하는 page table 시작주소를 얻는다, page번호는 offset d를 통해 얻는다, 4KB씩 잘리는걸 알고 있으니 p는 4KB로 나눈 값, d'는 나머지, >=기호는 segment length가 page 10개로 구성되어 10*4KB인데 d가 이보다 크다면 trap를 발생시킨다.  

의미단위로 나누어 장점도 얻고 외부조각도 생기지 않는다.